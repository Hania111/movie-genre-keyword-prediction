{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import json\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    hamming_loss,\n",
        "    jaccard_score,\n",
        ")\n",
        "import os\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "sNdZKA9nWr8D"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation"
      ],
      "metadata": {
        "id": "ISZcSBKcbsCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XTO-M-m6Wqfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb8c3b79-f61c-46fe-ba3d-80e75068128b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset = pd.read_csv(\"/content/drive/MyDrive/semestr 9/movie_dataset_prepared.csv\")"
      ],
      "metadata": {
        "id": "wCnIQYNsaPlJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset.head()\n",
        "\n",
        "movie_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fDTMLWDcbeBm",
        "outputId": "cdf04756-49b5-4882-9f74-7526b35ee611"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 genres_list  \\\n",
              "0          [28, 12, 14, 878]   \n",
              "1               [12, 14, 28]   \n",
              "2               [28, 12, 80]   \n",
              "3           [28, 80, 18, 53]   \n",
              "4              [28, 12, 878]   \n",
              "...                      ...   \n",
              "4795            [28, 80, 53]   \n",
              "4796             [35, 10749]   \n",
              "4797  [35, 18, 10749, 10770]   \n",
              "4798                      []   \n",
              "4799                    [99]   \n",
              "\n",
              "                                          keywords_list  \\\n",
              "0     [2964, 3801, 9840, 9882, 9951, 13065, 14643, 2...   \n",
              "1                                  [2038, 3799, 179430]   \n",
              "2                                [470, 818, 4289, 9663]   \n",
              "3                        [849, 949, 1308, 9715, 156395]   \n",
              "4        [818, 3801, 7376, 9951, 10685, 207928, 209714]   \n",
              "...                                                 ...   \n",
              "4795                                                 []   \n",
              "4796                                                 []   \n",
              "4797                                             [5340]   \n",
              "4798                                                 []   \n",
              "4799                                             [1523]   \n",
              "\n",
              "                                               overview  \n",
              "0     in the 22nd century a paraplegic marine is dis...  \n",
              "1     captain barbossa long believed to be dead has ...  \n",
              "2     a cryptic message from bonds past sends him on...  \n",
              "3     following the death of district attorney harve...  \n",
              "4     john carter is a warweary former military capt...  \n",
              "...                                                 ...  \n",
              "4795  el mariachi just wants to play his guitar and ...  \n",
              "4796  a newlywed couples honeymoon is upended by the...  \n",
              "4797  signed sealed delivered introduces a dedicated...  \n",
              "4798  when ambitious new york attorney sam is sent t...  \n",
              "4799  ever since the second grade when he first saw ...  \n",
              "\n",
              "[4800 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b1b06da1-1d3d-48fa-ad95-e66dc731ba84\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>genres_list</th>\n",
              "      <th>keywords_list</th>\n",
              "      <th>overview</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[28, 12, 14, 878]</td>\n",
              "      <td>[2964, 3801, 9840, 9882, 9951, 13065, 14643, 2...</td>\n",
              "      <td>in the 22nd century a paraplegic marine is dis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[12, 14, 28]</td>\n",
              "      <td>[2038, 3799, 179430]</td>\n",
              "      <td>captain barbossa long believed to be dead has ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[28, 12, 80]</td>\n",
              "      <td>[470, 818, 4289, 9663]</td>\n",
              "      <td>a cryptic message from bonds past sends him on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[28, 80, 18, 53]</td>\n",
              "      <td>[849, 949, 1308, 9715, 156395]</td>\n",
              "      <td>following the death of district attorney harve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[28, 12, 878]</td>\n",
              "      <td>[818, 3801, 7376, 9951, 10685, 207928, 209714]</td>\n",
              "      <td>john carter is a warweary former military capt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4795</th>\n",
              "      <td>[28, 80, 53]</td>\n",
              "      <td>[]</td>\n",
              "      <td>el mariachi just wants to play his guitar and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4796</th>\n",
              "      <td>[35, 10749]</td>\n",
              "      <td>[]</td>\n",
              "      <td>a newlywed couples honeymoon is upended by the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4797</th>\n",
              "      <td>[35, 18, 10749, 10770]</td>\n",
              "      <td>[5340]</td>\n",
              "      <td>signed sealed delivered introduces a dedicated...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4798</th>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>when ambitious new york attorney sam is sent t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4799</th>\n",
              "      <td>[99]</td>\n",
              "      <td>[1523]</td>\n",
              "      <td>ever since the second grade when he first saw ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4800 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1b06da1-1d3d-48fa-ad95-e66dc731ba84')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b1b06da1-1d3d-48fa-ad95-e66dc731ba84 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b1b06da1-1d3d-48fa-ad95-e66dc731ba84');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dfe9e191-d611-48d7-a64c-a87a516140c2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dfe9e191-d611-48d7-a64c-a87a516140c2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dfe9e191-d611-48d7-a64c-a87a516140c2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_7020f88f-d6da-4841-bc9e-2b53be5ac588\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('movie_dataset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7020f88f-d6da-4841-bc9e-2b53be5ac588 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('movie_dataset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_dataset",
              "summary": "{\n  \"name\": \"movie_dataset\",\n  \"rows\": 4800,\n  \"fields\": [\n    {\n      \"column\": \"genres_list\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1175,\n        \"samples\": [\n          \"[14, 12, 16]\",\n          \"[28, 35, 80, 18]\",\n          \"[12, 16, 10751, 14, 878]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords_list\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2643,\n        \"samples\": [\n          \"[1568, 10103, 18525]\",\n          \"[7312, 9663]\",\n          \"[90, 567, 572, 2483, 10776, 13130, 179431]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4799,\n        \"samples\": [\n          \"craig and smokey are two guys in los angeles hanging out on their porch on a friday afternoon smoking and drinking looking for something to do\",\n          \"set in 79 ad pompeii tells the epic story of milo a slave turned invincible gladiator who finds himself in a race against time to save his true love cassia the beautiful daughter of a wealthy merchant who has been unwillingly betrothed to a corrupt roman senator as mount vesuvius erupts in a torrent of blazing lava milo must fight his way out of the arena in order to save his beloved as the once magnificent pompeii crumbles around him\",\n          \"two women nic and jules brought a son and daughter into the world through artificial insemination when one of their children reaches age both kids go behind their mothers backs to meet with the donor life becomes so much more interesting when the father two mothers and children start to become attached to each other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movie_dataset = movie_dataset[['overview', 'keywords_list']].copy()\n",
        "\n",
        "movie_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "doqhExSEKrN6",
        "outputId": "842c8127-d5aa-40d2-babd-f74ee4ddf565"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            overview  \\\n",
              "0  in the 22nd century a paraplegic marine is dis...   \n",
              "1  captain barbossa long believed to be dead has ...   \n",
              "2  a cryptic message from bonds past sends him on...   \n",
              "3  following the death of district attorney harve...   \n",
              "4  john carter is a warweary former military capt...   \n",
              "\n",
              "                                       keywords_list  \n",
              "0  [2964, 3801, 9840, 9882, 9951, 13065, 14643, 2...  \n",
              "1                               [2038, 3799, 179430]  \n",
              "2                             [470, 818, 4289, 9663]  \n",
              "3                     [849, 949, 1308, 9715, 156395]  \n",
              "4     [818, 3801, 7376, 9951, 10685, 207928, 209714]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0de67248-4376-4e8a-9fd4-9e64eb0f745c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overview</th>\n",
              "      <th>keywords_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>in the 22nd century a paraplegic marine is dis...</td>\n",
              "      <td>[2964, 3801, 9840, 9882, 9951, 13065, 14643, 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>captain barbossa long believed to be dead has ...</td>\n",
              "      <td>[2038, 3799, 179430]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a cryptic message from bonds past sends him on...</td>\n",
              "      <td>[470, 818, 4289, 9663]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>following the death of district attorney harve...</td>\n",
              "      <td>[849, 949, 1308, 9715, 156395]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>john carter is a warweary former military capt...</td>\n",
              "      <td>[818, 3801, 7376, 9951, 10685, 207928, 209714]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0de67248-4376-4e8a-9fd4-9e64eb0f745c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0de67248-4376-4e8a-9fd4-9e64eb0f745c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0de67248-4376-4e8a-9fd4-9e64eb0f745c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-50d6159b-cacd-4633-94d8-bd042f005a96\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-50d6159b-cacd-4633-94d8-bd042f005a96')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-50d6159b-cacd-4633-94d8-bd042f005a96 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_dataset",
              "summary": "{\n  \"name\": \"movie_dataset\",\n  \"rows\": 4800,\n  \"fields\": [\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4799,\n        \"samples\": [\n          \"craig and smokey are two guys in los angeles hanging out on their porch on a friday afternoon smoking and drinking looking for something to do\",\n          \"set in 79 ad pompeii tells the epic story of milo a slave turned invincible gladiator who finds himself in a race against time to save his true love cassia the beautiful daughter of a wealthy merchant who has been unwillingly betrothed to a corrupt roman senator as mount vesuvius erupts in a torrent of blazing lava milo must fight his way out of the arena in order to save his beloved as the once magnificent pompeii crumbles around him\",\n          \"two women nic and jules brought a son and daughter into the world through artificial insemination when one of their children reaches age both kids go behind their mothers backs to meet with the donor life becomes so much more interesting when the father two mothers and children start to become attached to each other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords_list\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2643,\n        \"samples\": [\n          \"[1568, 10103, 18525]\",\n          \"[7312, 9663]\",\n          \"[90, 567, 572, 2483, 10776, 13130, 179431]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# metod for oversampling imbalanced data\n",
        "\n",
        "def oversample_multilabel(X, y, target_strategy=\"max\", random_state=42):\n",
        "    \"\"\"\n",
        "    Simple oversampling for multi-label data:\n",
        "    - X: np.array (n_samples, max_len)\n",
        "    - y: np.array (n_samples, n_classes) with 0/1 values\n",
        "    - target_strategy:\n",
        "        \"max\"  -> upsample each label to the count of the most frequent one\n",
        "        \"mean\" -> upsample each label to the average label frequency\n",
        "    Returns: X_bal, y_bal\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "\n",
        "\n",
        "    label_counts = y.sum(axis=0).astype(int)\n",
        "    if target_strategy == \"max\":\n",
        "        target = label_counts.max()\n",
        "    elif target_strategy == \"mean\":\n",
        "        target = int(label_counts.mean())\n",
        "    else:\n",
        "        raise ValueError(\"target_strategy must be 'max' or 'mean'\")\n",
        "\n",
        "    n_classes = y.shape[1]\n",
        "\n",
        "\n",
        "    idx_per_label = {\n",
        "        c: np.where(y[:, c] == 1)[0]\n",
        "        for c in range(n_classes)\n",
        "    }\n",
        "\n",
        "    X_list = [X]\n",
        "    y_list = [y]\n",
        "\n",
        "    for c in range(n_classes):\n",
        "        deficit = target - label_counts[c]\n",
        "        if deficit <= 0:\n",
        "            continue\n",
        "\n",
        "\n",
        "        candidate_idx = idx_per_label[c]\n",
        "        if len(candidate_idx) == 0:\n",
        "            continue\n",
        "\n",
        "\n",
        "        sampled_idx = rng.choice(candidate_idx, size=deficit, replace=True)\n",
        "        X_list.append(X[sampled_idx])\n",
        "        y_list.append(y[sampled_idx])\n",
        "\n",
        "\n",
        "    X_bal = np.concatenate(X_list, axis=0)\n",
        "    y_bal = np.concatenate(y_list, axis=0)\n",
        "\n",
        "    perm = rng.permutation(len(X_bal))\n",
        "    X_bal = X_bal[perm]\n",
        "    y_bal = y_bal[perm]\n",
        "\n",
        "    return X_bal, y_bal"
      ],
      "metadata": {
        "id": "2H8qGJ2pASKZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining max_len value for lstm\n",
        "\n",
        "# 1. Calculate sequence lengths\n",
        "seq_lengths = [len(str(text).split()) for text in movie_dataset['overview']]\n",
        "\n",
        "\n",
        "# 2. Calculate percentiles\n",
        "p90 = np.percentile(seq_lengths, 90)\n",
        "p95 = np.percentile(seq_lengths, 95)\n",
        "p98 = np.percentile(seq_lengths, 98)\n",
        "max_val = np.max(seq_lengths)\n",
        "\n",
        "# 3. Print results\n",
        "print(f\"--- Sequence Length Statistics ---\")\n",
        "print(f\"Mean length: {np.mean(seq_lengths):.2f} words\")\n",
        "print(f\"Max length: {max_val} words\")\n",
        "print(f\"-\" * 30)\n",
        "print(f\"90% of descriptions fit in: {int(p90)} words\")\n",
        "print(f\"95% of descriptions fit in: {int(p95)} words  <-- RECOMMENDED FOR MAX_LEN\")\n",
        "print(f\"98% of descriptions fit in: {int(p98)} words\")\n",
        "\n",
        "# 4. Plot histogram\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(seq_lengths, bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "plt.axvline(p95, color='red', linestyle='dashed', linewidth=2, label=f'95th Percentile ({int(p95)})')\n",
        "plt.title('Distribution of Description Lengths (overview)')\n",
        "plt.xlabel('Number of Words')\n",
        "plt.ylabel('Number of Movies')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        },
        "id": "dWBzJ7puaeDY",
        "outputId": "4e824b1b-0fdc-4e56-bfd7-dc932a152e48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Sequence Length Statistics ---\n",
            "Mean length: 51.98 words\n",
            "Max length: 175 words\n",
            "------------------------------\n",
            "90% of descriptions fit in: 85 words\n",
            "95% of descriptions fit in: 107 words  <-- RECOMMENDED FOR MAX_LEN\n",
            "98% of descriptions fit in: 129 words\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# createing small dataset for testing purposes\n",
        "\n",
        "movie_dataset_small = movie_dataset.sample(n=100, random_state=42)\n",
        "\n",
        "movie_dataset = movie_dataset_small\n",
        "\n",
        "movie_dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5ydigXjHb9Kt",
        "outputId": "880063cc-89bc-48bf-a9cb-9b3025c9644e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               overview         keywords_list\n",
              "596   when the switchblade the most sophisticated pr...  [1930, 4289, 187056]\n",
              "3370  when street smart rapper christopher cnote haw...                [6075]\n",
              "3048  as their first year of high school looms ahead...         [6270, 13130]\n",
              "2908  a young woman becomes inexplicably attracted t...                [9937]\n",
              "8     as harry begins his sixth year at hogwarts he ...    [616, 2343, 12564]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eb28a47a-44e4-48a5-9ea0-d11f5f116cec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>overview</th>\n",
              "      <th>keywords_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>when the switchblade the most sophisticated pr...</td>\n",
              "      <td>[1930, 4289, 187056]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3370</th>\n",
              "      <td>when street smart rapper christopher cnote haw...</td>\n",
              "      <td>[6075]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3048</th>\n",
              "      <td>as their first year of high school looms ahead...</td>\n",
              "      <td>[6270, 13130]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2908</th>\n",
              "      <td>a young woman becomes inexplicably attracted t...</td>\n",
              "      <td>[9937]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>as harry begins his sixth year at hogwarts he ...</td>\n",
              "      <td>[616, 2343, 12564]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb28a47a-44e4-48a5-9ea0-d11f5f116cec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eb28a47a-44e4-48a5-9ea0-d11f5f116cec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eb28a47a-44e4-48a5-9ea0-d11f5f116cec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8f521131-a5ba-46af-b98a-196e1ec85c0d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f521131-a5ba-46af-b98a-196e1ec85c0d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8f521131-a5ba-46af-b98a-196e1ec85c0d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "movie_dataset",
              "summary": "{\n  \"name\": \"movie_dataset\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"overview\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"world war i has left golfer rannulph junuh a pokerplaying alcoholic his perfect swing gone now however he needs to get it back to play in a tournament to save the financially ravaged golf course of a longago sweetheart help arrives in the form of mysterious caddy bagger vance\",\n          \"after the lord of darkness decides he will not cede his thrown to any of his three sons the two most powerful of them escape to earth to create a kingdom for themselves this action closes the portal filtering sinful souls to hell and causes satan to wither away he must send his most weak but beloved son little nicky to earth to return his brothers to hell\",\n          \"three teenage girls come of age while working at a pizza parlor in mystic connecticut\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keywords_list\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 80,\n        \"samples\": [\n          \"[392, 13014, 223438]\",\n          \"[1930, 4289, 187056]\",\n          \"[2038, 2251, 5091, 6027, 7879, 10103, 13072, 14534, 187056]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenazation and padding for overwiew\n",
        "movie_dataset['overview'] = movie_dataset['overview'].fillna('').astype(str)\n",
        "\n",
        "\n",
        "# checking the number of unique words to better estimate size of the vocabulary (max_features)\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(movie_dataset['overview'])\n",
        "print(\"Unique words:\", len(tokenizer.word_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szm0uHkFKVme",
        "outputId": "e6820f3a-d1d0-47b7-fdbe-544ddec05d20"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique words: 1981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "max_len = 128\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
        "tokenizer.fit_on_texts(movie_dataset['overview'].values)\n",
        "X = tokenizer.texts_to_sequences(movie_dataset['overview'].values)\n",
        "X = pad_sequences(X, max_len)"
      ],
      "metadata": {
        "id": "NSWKnvZkLE7V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# multi-label binarization\n",
        "\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(movie_dataset[\"keywords_list\"])\n",
        "keywords_classes = mlb.classes_\n",
        "num_classes = len(keywords_classes)\n",
        "\n",
        "y_for_split = np.argmax(y, axis=1)"
      ],
      "metadata": {
        "id": "QhCN6_0ONffq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_splits = 5\n",
        "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "vdYrjvkoOLNp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manually specified (non-default) hyperparameters of the model architecture:\n",
        "\n",
        "- input_dim=10000 - sice of the vocabulary (based on the number of unique words)  \n",
        "- output_dim=100 - length of embeding vector, value 100 is commonly use for the model. It was not tunned because of it low impact on model and to reduce computatino time  \n",
        "- Dense(64, activation='relu') â€“ a dense layer with ReLU activation (it allowes model to lern more complex representatinos)  \n",
        "- Dense(num_classes, activation='sigmoid') - defining how many class we have, sigmoid for multi-label classification\n",
        "- Nr of epochs - 15 (with early dtop added)\n",
        "\n",
        "The parameters we will be tuning:\n",
        "\n",
        "- the number of LSTM units  \n",
        "- dropout - to reduce overfitting"
      ],
      "metadata": {
        "id": "SZSPG6jjOPkM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVE_MODEL_DIR = \"/content/drive/MyDrive/lstm_keywords/models_1\"\n",
        "os.makedirs(SAVE_MODEL_DIR, exist_ok=True)\n",
        "\n",
        "RESULTS_DIR = \"/content/drive/MyDrive/lstm_keywords/results_1\"\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "param_grid = list(ParameterGrid({\n",
        "    'lstm_units': [64, 128],\n",
        "    'dropout_rate': [0.3, 0.5],\n",
        "}))\n",
        "\n",
        "fold_results = []\n",
        "metrics_all = {\n",
        "    'accuracy': {str(p): [] for p in param_grid},\n",
        "    'precision': {str(p): [] for p in param_grid},\n",
        "    'recall': {str(p): [] for p in param_grid},\n",
        "    'f1': {str(p): [] for p in param_grid},\n",
        "    'hamming_loss': {str(p): [] for p in param_grid},\n",
        "    'f1_macro':          {str(p): [] for p in param_grid},\n",
        "    'f1_micro':          {str(p): [] for p in param_grid},\n",
        "    'precision_macro':   {str(p): [] for p in param_grid},\n",
        "    'precision_micro':   {str(p): [] for p in param_grid},\n",
        "    'recall_macro':      {str(p): [] for p in param_grid},\n",
        "    'recall_micro':      {str(p): [] for p in param_grid},\n",
        "    'hamming_accuracy':  {str(p): [] for p in param_grid},\n",
        "    'jaccard_samples':   {str(p): [] for p in param_grid},\n",
        "}\n",
        "\n",
        "\n",
        "predictions_all = {str(p): {'y_true': [], 'y_pred': []} for p in param_grid}\n",
        "\n",
        "\n",
        "def create_model(lstm_units, dropout_rate, num_classes, max_features, max_len):\n",
        "    \"\"\"Create Bidirectional LSTM model with given parameters\"\"\"\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=10000, output_dim=100),\n",
        "        Bidirectional(LSTM(lstm_units, return_sequences=True)),\n",
        "        Dropout(dropout_rate),\n",
        "        Bidirectional(LSTM(lstm_units // 2)),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(dropout_rate),\n",
        "        Dense(num_classes, activation='sigmoid')  # Multi-label: sigmoid\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        loss='binary_crossentropy',  # Multi-label: binary_crossentropy\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "# Grid Search with Cross-Validation\n",
        "print(\"Starting Grid Search with Cross-Validation...\\n\")\n",
        "print(f\"Total combinations: {len(param_grid)}\")\n",
        "print(f\"Total folds per combination: {n_splits}\")\n",
        "print(f\"Total models to train: {len(param_grid) * n_splits}\")\n",
        "print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "results_file = 'grid_search_results.json'\n",
        "\n",
        "\n",
        "for param_idx, params in enumerate(param_grid):\n",
        "  p_str = str(params)\n",
        "\n",
        "  print(\"=\"*80)\n",
        "  print(f\"COMBINATION {param_idx + 1}/{len(param_grid)}\")\n",
        "  print(\"=\"*80)\n",
        "  print(f\"Parameters: {params}\")\n",
        "  print(f\"Started at: {datetime.now().strftime('%H:%M:%S')}\")\n",
        "  print(\"-\"*80)\n",
        "\n",
        "  for fold, (train_idx, val_idx) in enumerate(kf.split(X, y_for_split)):\n",
        "    print(f\"\\n  FOLD {fold + 1}/{n_splits}\")\n",
        "    print(f\"  Training samples: {len(train_idx)}, Validation samples: {len(val_idx)}\")\n",
        "\n",
        "    X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
        "    y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
        "\n",
        "    X_train_fold, y_train_fold = oversample_multilabel(\n",
        "        X_train_fold,\n",
        "        y_train_fold,\n",
        "        target_strategy=\"mean\",\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "\n",
        "    model = create_model(\n",
        "            lstm_units=params['lstm_units'],\n",
        "            dropout_rate=params['dropout_rate'],\n",
        "            num_classes=num_classes,\n",
        "            max_features=max_features,\n",
        "            max_len = max_len\n",
        "        )\n",
        "\n",
        "    model_name = (\n",
        "        f\"lstm_units{params['lstm_units']}_\"\n",
        "        f\"drop{params['dropout_rate']}_\"\n",
        "        f\"fold{fold+1}.keras\"\n",
        "    )\n",
        "    checkpoint_path = os.path.join(SAVE_MODEL_DIR, model_name)\n",
        "\n",
        "\n",
        "    early_stop = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=6,\n",
        "            restore_best_weights=True,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath=checkpoint_path,\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True,\n",
        "        save_weights_only=False,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    print(f\"  Training...\")\n",
        "    history = model.fit(\n",
        "            X_train_fold, y_train_fold,\n",
        "            validation_data=(X_val_fold, y_val_fold),\n",
        "            epochs=30,\n",
        "            batch_size=32,\n",
        "            callbacks=[early_stop, checkpoint],\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "    # Show training summary\n",
        "    final_epoch = len(history.history['loss'])\n",
        "    print(f\"\\n  Completed {final_epoch} epochs (early stopped: {final_epoch < 15})\")\n",
        "    print(f\"  Final training loss: {history.history['loss'][-1]:.4f}\")\n",
        "    print(f\"  Final validation loss: {history.history['val_loss'][-1]:.4f}\")\n",
        "    print(f\"  Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
        "\n",
        "    y_pred_probs = model.predict(X_val_fold, verbose=0)\n",
        "    y_pred = (y_pred_probs > 0.5).astype(int)  # Multi-label threshold\n",
        "\n",
        "    predictions_all[p_str]['y_true'].extend(y_val_fold)\n",
        "    predictions_all[p_str]['y_pred'].extend(y_pred)\n",
        "\n",
        "    acc = accuracy_score(y_val_fold, y_pred)\n",
        "    prec = precision_score(y_val_fold, y_pred, average='samples', zero_division=0)\n",
        "    rec = recall_score(y_val_fold, y_pred, average='samples', zero_division=0)\n",
        "    f1 = f1_score(y_val_fold, y_pred, average='samples', zero_division=0)\n",
        "    h_loss = hamming_loss(y_val_fold, y_pred)\n",
        "    f1_macro = f1_score(y_val_fold, y_pred, average='macro', zero_division=0)\n",
        "    f1_micro = f1_score(y_val_fold, y_pred, average='micro', zero_division=0)\n",
        "    prec_macro = precision_score(y_val_fold, y_pred, average='macro', zero_division=0)\n",
        "    prec_micro = precision_score(y_val_fold, y_pred, average='micro', zero_division=0)\n",
        "    rec_macro = recall_score(y_val_fold, y_pred, average='macro', zero_division=0)\n",
        "    rec_micro = recall_score(y_val_fold, y_pred, average='micro', zero_division=0)\n",
        "    h_acc = 1.0 - h_loss\n",
        "    jacc = jaccard_score(y_val_fold, y_pred, average='samples')\n",
        "\n",
        "    metrics_all['accuracy'][p_str].append(acc)\n",
        "    metrics_all['precision'][p_str].append(prec)\n",
        "    metrics_all['recall'][p_str].append(rec)\n",
        "    metrics_all['f1'][p_str].append(f1)\n",
        "    metrics_all['hamming_loss'][p_str].append(h_loss)\n",
        "    metrics_all['f1_macro'][p_str].append(f1_macro)\n",
        "    metrics_all['f1_micro'][p_str].append(f1_micro)\n",
        "    metrics_all['precision_macro'][p_str].append(prec_macro)\n",
        "    metrics_all['precision_micro'][p_str].append(prec_micro)\n",
        "    metrics_all['recall_macro'][p_str].append(rec_macro)\n",
        "    metrics_all['recall_micro'][p_str].append(rec_micro)\n",
        "    metrics_all['hamming_accuracy'][p_str].append(h_acc)\n",
        "    metrics_all['jaccard_samples'][p_str].append(jacc)\n",
        "\n",
        "    print(f\"\\n  FOLD {fold + 1} RESULTS:\")\n",
        "    print(f\"    Accuracy:      {acc:.4f}\")\n",
        "    print(f\"    Precision:     {prec:.4f}\")\n",
        "    print(f\"    Recall:        {rec:.4f}\")\n",
        "    print(f\"    F1 Score:      {f1:.4f}\")\n",
        "    print(f\"    Hamming Loss:  {h_loss:.4f}\")\n",
        "    print(f\"    Hamming Accuracy:     {h_acc:.4f}\")\n",
        "    print(f\"    F1 Macro:             {f1_macro:.4f}\")\n",
        "    print(f\"    F1 Micro:             {f1_micro:.4f}\")\n",
        "    print(f\"    Jaccard (samples):    {jacc:.4f}\")\n",
        "\n",
        "    fold_results.append({\n",
        "            'fold': fold + 1,\n",
        "            'accuracy': float(acc),\n",
        "            'precision': float(prec),\n",
        "            'recall': float(rec),\n",
        "            'f1': float(f1),\n",
        "            'hamming_loss': float(h_loss),\n",
        "            'hamming_accuracy': float(h_acc),\n",
        "            'f1_macro': float(f1_macro),\n",
        "            'f1_micro': float(f1_micro),\n",
        "            'precision_macro': float(prec_macro),\n",
        "            'precision_micro': float(prec_micro),\n",
        "            'recall_macro': float(rec_macro),\n",
        "            'recall_micro': float(rec_micro),\n",
        "            'jaccard_samples': float(jacc),\n",
        "            'epochs_trained': final_epoch,\n",
        "            'final_train_loss': float(history.history['loss'][-1]),\n",
        "            'final_val_loss': float(history.history['val_loss'][-1])\n",
        "        })\n",
        "\n",
        "  avg_acc = np.mean(metrics_all['accuracy'][p_str])\n",
        "  avg_prec = np.mean(metrics_all['precision'][p_str])\n",
        "  avg_rec = np.mean(metrics_all['recall'][p_str])\n",
        "  avg_f1 = np.mean(metrics_all['f1'][p_str])\n",
        "  avg_h_loss = np.mean(metrics_all['hamming_loss'][p_str])\n",
        "  avg_f1_macro = np.mean(metrics_all['f1_macro'][p_str])\n",
        "  avg_f1_micro = np.mean(metrics_all['f1_micro'][p_str])\n",
        "  avg_h_acc = np.mean(metrics_all['hamming_accuracy'][p_str])\n",
        "  avg_jacc = np.mean(metrics_all['jaccard_samples'][p_str])\n",
        "\n",
        "  print(\"\\n\" + \"=\"*80)\n",
        "  print(f\"COMBINATION {param_idx + 1} SUMMARY\")\n",
        "  print(\"=\"*80)\n",
        "  print(f\"Parameters: {params}\")\n",
        "  print(f\"Average Accuracy:      {avg_acc:.4f} (+/- {np.std(metrics_all['accuracy'][p_str]):.4f})\")\n",
        "  print(f\"Average Precision:     {avg_prec:.4f} (+/- {np.std(metrics_all['precision'][p_str]):.4f})\")\n",
        "  print(f\"Average Recall:        {avg_rec:.4f} (+/- {np.std(metrics_all['recall'][p_str]):.4f})\")\n",
        "  print(f\"Average F1 Score:      {avg_f1:.4f} (+/- {np.std(metrics_all['f1'][p_str]):.4f})\")\n",
        "  print(f\"Average Hamming Loss:  {avg_h_loss:.4f} (+/- {np.std(metrics_all['hamming_loss'][p_str]):.4f})\")\n",
        "  print(f\"Average Hamming Accuracy: {avg_h_acc:.4f}\")\n",
        "  print(f\"Average F1 Macro:         {avg_f1_macro:.4f}\")\n",
        "  print(f\"Average F1 Micro:         {avg_f1_micro:.4f}\")\n",
        "  print(f\"Average Jaccard (samples):{avg_jacc:.4f}\")\n",
        "  print(f\"Completed at: {datetime.now().strftime('%H:%M:%S')}\\n\")\n",
        "\n",
        "  # Save intermediate results to file (in case of crash)\n",
        "  intermediate_results = {\n",
        "      'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
        "      'completed_combinations': param_idx + 1,\n",
        "      'total_combinations': len(param_grid),\n",
        "      'params': params,\n",
        "      'fold_results': fold_results,\n",
        "      'summary': {\n",
        "          'avg_accuracy': float(avg_acc),\n",
        "          'std_accuracy': float(np.std(metrics_all['accuracy'][p_str])),\n",
        "          'avg_precision': float(avg_prec),\n",
        "          'avg_recall': float(avg_rec),\n",
        "          'avg_f1': float(avg_f1),\n",
        "          'std_f1': float(np.std(metrics_all['f1'][p_str])),\n",
        "          'avg_hamming_loss': float(avg_h_loss),\n",
        "          'avg_hamming_accuracy': float(avg_h_acc),\n",
        "          'avg_f1_macro': float(avg_f1_macro),\n",
        "          'avg_f1_micro': float(avg_f1_micro),\n",
        "          'avg_jaccard_samples': float(avg_jacc),\n",
        "      }\n",
        "  }\n",
        "\n",
        "  # Append to file\n",
        "  results_file = os.path.join(RESULTS_DIR, \"grid_search_results.json\")\n",
        "\n",
        "  try:\n",
        "      with open(results_file, 'r') as f:\n",
        "          all_results = json.load(f)\n",
        "  except FileNotFoundError:\n",
        "      all_results = []\n",
        "\n",
        "  all_results.append(intermediate_results)\n",
        "\n",
        "  with open(results_file, 'w') as f:\n",
        "      json.dump(all_results, f, indent=2)\n",
        "\n",
        "  print(f\"âœ“ Results saved to {results_file}\\n\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"GRID SEARCH COMPLETED!\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Finished at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "\n",
        "summary_df = pd.DataFrame({\n",
        "    'params': list(metrics_all['f1'].keys()),\n",
        "    'accuracy_mean': [np.mean(metrics_all['accuracy'][p]) for p in metrics_all['accuracy']],\n",
        "    'accuracy_std': [np.std(metrics_all['accuracy'][p]) for p in metrics_all['accuracy']],\n",
        "    'precision_mean': [np.mean(metrics_all['precision'][p]) for p in metrics_all['precision']],\n",
        "    'recall_mean': [np.mean(metrics_all['recall'][p]) for p in metrics_all['recall']],\n",
        "    'f1_mean': [np.mean(metrics_all['f1'][p]) for p in metrics_all['f1']],\n",
        "    'f1_std': [np.std(metrics_all['f1'][p]) for p in metrics_all['f1']],\n",
        "    'hamming_loss_mean': [np.mean(metrics_all['hamming_loss'][p]) for p in metrics_all['hamming_loss']],\n",
        "    'f1_macro_mean':       [np.mean(metrics_all['f1_macro'][p]) for p in metrics_all['f1_macro']],\n",
        "    'f1_micro_mean':       [np.mean(metrics_all['f1_micro'][p]) for p in metrics_all['f1_micro']],\n",
        "    'hamming_accuracy_mean':[np.mean(metrics_all['hamming_accuracy'][p]) for p in metrics_all['hamming_accuracy']],\n",
        "    'jaccard_samples_mean':[np.mean(metrics_all['jaccard_samples'][p]) for p in metrics_all['jaccard_samples']],\n",
        "})\n",
        "\n",
        "summary_df = summary_df.sort_values('f1_mean', ascending=False)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"CROSS-VALIDATION RESULTS (sorted by F1 score)\")\n",
        "print(\"=\"*80)\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "# Save final summary\n",
        "summary_df.to_csv('final_grid_search_summary.csv', index=False)\n",
        "print(f\"\\nâœ“ Final summary saved to 'final_grid_search_summary.csv'\")\n",
        "\n",
        "# Get best parameters\n",
        "best_params_str = summary_df.iloc[0]['params']\n",
        "best_params = eval(best_params_str)\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BEST PARAMETERS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Parameters: {best_params}\")\n",
        "print(f\"F1 Score: {summary_df.iloc[0]['f1_mean']:.4f} (+/- {summary_df.iloc[0]['f1_std']:.4f})\")\n",
        "print(f\"Accuracy: {summary_df.iloc[0]['accuracy_mean']:.4f} (+/- {summary_df.iloc[0]['accuracy_std']:.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HoDMjFlOUyV",
        "outputId": "2a0ded6b-d823-47e3-d76b-a75f92541638"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Grid Search with Cross-Validation...\n",
            "\n",
            "Total combinations: 4\n",
            "Total folds per combination: 5\n",
            "Total models to train: 20\n",
            "Started at: 2025-12-03 19:38:04\n",
            "\n",
            "================================================================================\n",
            "COMBINATION 1/4\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.3, 'lstm_units': 64}\n",
            "Started at: 19:38:04\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  FOLD 1/5\n",
            "  Training samples: 80, Validation samples: 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0592 - loss: 0.6919\n",
            "Epoch 1: val_loss improved from inf to 0.68695, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 196ms/step - accuracy: 0.0583 - loss: 0.6914 - val_accuracy: 0.0000e+00 - val_loss: 0.6870\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0807 - loss: 0.6786\n",
            "Epoch 2: val_loss improved from 0.68695 to 0.67118, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0843 - loss: 0.6779 - val_accuracy: 0.0000e+00 - val_loss: 0.6712\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0762 - loss: 0.6577\n",
            "Epoch 3: val_loss improved from 0.67118 to 0.65062, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0719 - loss: 0.6570 - val_accuracy: 0.0500 - val_loss: 0.6506\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0592 - loss: 0.6329\n",
            "Epoch 4: val_loss improved from 0.65062 to 0.63802, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.0606 - loss: 0.6306 - val_accuracy: 0.0000e+00 - val_loss: 0.6380\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0638 - loss: 0.6385\n",
            "Epoch 5: val_loss improved from 0.63802 to 0.62992, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0566 - loss: 0.6327 - val_accuracy: 0.0000e+00 - val_loss: 0.6299\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0391 - loss: 0.6038\n",
            "Epoch 6: val_loss did not improve from 0.62992\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0425 - loss: 0.6039 - val_accuracy: 0.0000e+00 - val_loss: 0.6302\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0319 - loss: 0.5848    \n",
            "Epoch 7: val_loss did not improve from 0.62992\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0354 - loss: 0.5865 - val_accuracy: 0.0000e+00 - val_loss: 0.6372\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0065 - loss: 0.5691    \n",
            "Epoch 8: val_loss did not improve from 0.62992\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0114 - loss: 0.5679 - val_accuracy: 0.0000e+00 - val_loss: 0.6395\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0352 - loss: 0.5234\n",
            "Epoch 9: val_loss improved from 0.62992 to 0.62442, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.0328 - loss: 0.5264 - val_accuracy: 0.1000 - val_loss: 0.6244\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0208 - loss: 0.5322\n",
            "Epoch 10: val_loss did not improve from 0.62442\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0186 - loss: 0.5278 - val_accuracy: 0.1000 - val_loss: 0.6279\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0293 - loss: 0.4938\n",
            "Epoch 11: val_loss did not improve from 0.62442\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0266 - loss: 0.4950 - val_accuracy: 0.1000 - val_loss: 0.6681\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0020 - loss: 0.5020    \n",
            "Epoch 12: val_loss did not improve from 0.62442\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0060 - loss: 0.4990 - val_accuracy: 0.1000 - val_loss: 0.6719\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0514 - loss: 0.4928\n",
            "Epoch 13: val_loss did not improve from 0.62442\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0578 - loss: 0.4898 - val_accuracy: 0.0500 - val_loss: 0.6849\n",
            "Epoch 14/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0488 - loss: 0.4875\n",
            "Epoch 14: val_loss did not improve from 0.62442\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0560 - loss: 0.4797 - val_accuracy: 0.0000e+00 - val_loss: 0.6906\n",
            "Epoch 15/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0065 - loss: 0.4701    \n",
            "Epoch 15: val_loss did not improve from 0.62442\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0090 - loss: 0.4637 - val_accuracy: 0.0500 - val_loss: 0.6537\n",
            "\n",
            "  Completed 15 epochs (early stopped: False)\n",
            "  Final training loss: 0.4507\n",
            "  Final validation loss: 0.6537\n",
            "  Best validation loss: 0.6244\n",
            "\n",
            "  FOLD 1 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.6089\n",
            "    Recall:        0.9217\n",
            "    F1 Score:      0.6873\n",
            "    Hamming Loss:  0.4143\n",
            "    Hamming Accuracy:     0.5857\n",
            "    F1 Macro:             0.6639\n",
            "    F1 Micro:             0.7225\n",
            "    Jaccard (samples):    0.5633\n",
            "\n",
            "  FOLD 2/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0846 - loss: 0.6921\n",
            "Epoch 1: val_loss improved from inf to 0.67996, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step - accuracy: 0.0884 - loss: 0.6912 - val_accuracy: 0.1500 - val_loss: 0.6800\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1270 - loss: 0.6706\n",
            "Epoch 2: val_loss improved from 0.67996 to 0.64954, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.1212 - loss: 0.6690 - val_accuracy: 0.1500 - val_loss: 0.6495\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0742 - loss: 0.6345\n",
            "Epoch 3: val_loss improved from 0.64954 to 0.61940, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.0700 - loss: 0.6321 - val_accuracy: 0.1500 - val_loss: 0.6194\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0820 - loss: 0.6005\n",
            "Epoch 4: val_loss improved from 0.61940 to 0.61274, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0752 - loss: 0.5994 - val_accuracy: 0.1500 - val_loss: 0.6127\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 0.5964\n",
            "Epoch 5: val_loss improved from 0.61274 to 0.60186, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0317 - loss: 0.5967 - val_accuracy: 0.1500 - val_loss: 0.6019\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0521 - loss: 0.5999\n",
            "Epoch 6: val_loss improved from 0.60186 to 0.59567, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.0530 - loss: 0.5984 - val_accuracy: 0.0500 - val_loss: 0.5957\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0632 - loss: 0.5809\n",
            "Epoch 7: val_loss improved from 0.59567 to 0.59169, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0581 - loss: 0.5807 - val_accuracy: 0.0500 - val_loss: 0.5917\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0150 - loss: 0.5697    \n",
            "Epoch 8: val_loss did not improve from 0.59169\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0168 - loss: 0.5677 - val_accuracy: 0.1500 - val_loss: 0.5933\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0215 - loss: 0.5587    \n",
            "Epoch 9: val_loss did not improve from 0.59169\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0257 - loss: 0.5540 - val_accuracy: 0.1500 - val_loss: 0.6051\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0221 - loss: 0.5177\n",
            "Epoch 10: val_loss did not improve from 0.59169\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0262 - loss: 0.5222 - val_accuracy: 0.0500 - val_loss: 0.6265\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0202 - loss: 0.4962\n",
            "Epoch 11: val_loss did not improve from 0.59169\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0203 - loss: 0.4975 - val_accuracy: 0.1000 - val_loss: 0.6774\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0378 - loss: 0.4879\n",
            "Epoch 12: val_loss did not improve from 0.59169\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0389 - loss: 0.4841 - val_accuracy: 0.0000e+00 - val_loss: 0.7052\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0430 - loss: 0.4852\n",
            "Epoch 13: val_loss did not improve from 0.59169\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0423 - loss: 0.4812 - val_accuracy: 0.0000e+00 - val_loss: 0.6683\n",
            "\n",
            "  Completed 13 epochs (early stopped: True)\n",
            "  Final training loss: 0.4733\n",
            "  Final validation loss: 0.6683\n",
            "  Best validation loss: 0.5917\n",
            "\n",
            "  FOLD 2 RESULTS:\n",
            "    Accuracy:      0.2000\n",
            "    Precision:     0.6536\n",
            "    Recall:        1.0000\n",
            "    F1 Score:      0.7459\n",
            "    Hamming Loss:  0.3464\n",
            "    Hamming Accuracy:     0.6536\n",
            "    F1 Macro:             0.7803\n",
            "    F1 Micro:             0.7905\n",
            "    Jaccard (samples):    0.6536\n",
            "\n",
            "  FOLD 3/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0495 - loss: 0.6910\n",
            "Epoch 1: val_loss improved from inf to 0.68236, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - accuracy: 0.0421 - loss: 0.6899 - val_accuracy: 0.1000 - val_loss: 0.6824\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0430 - loss: 0.6711\n",
            "Epoch 2: val_loss improved from 0.68236 to 0.66441, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0378 - loss: 0.6698 - val_accuracy: 0.1000 - val_loss: 0.6644\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0384 - loss: 0.6429\n",
            "Epoch 3: val_loss improved from 0.66441 to 0.65701, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0416 - loss: 0.6422 - val_accuracy: 0.1000 - val_loss: 0.6570\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0339 - loss: 0.6217\n",
            "Epoch 4: val_loss improved from 0.65701 to 0.64748, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0363 - loss: 0.6218 - val_accuracy: 0.0500 - val_loss: 0.6475\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0150 - loss: 0.5994    \n",
            "Epoch 5: val_loss improved from 0.64748 to 0.63705, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.0237 - loss: 0.6011 - val_accuracy: 0.0500 - val_loss: 0.6371\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0521 - loss: 0.5971\n",
            "Epoch 6: val_loss improved from 0.63705 to 0.62785, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0484 - loss: 0.5956 - val_accuracy: 0.0500 - val_loss: 0.6278\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0326 - loss: 0.5798\n",
            "Epoch 7: val_loss improved from 0.62785 to 0.62228, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0263 - loss: 0.5752 - val_accuracy: 0.0500 - val_loss: 0.6223\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0176 - loss: 0.5406    \n",
            "Epoch 8: val_loss improved from 0.62228 to 0.61195, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step - accuracy: 0.0186 - loss: 0.5404 - val_accuracy: 0.0500 - val_loss: 0.6120\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0514 - loss: 0.5175\n",
            "Epoch 9: val_loss did not improve from 0.61195\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0480 - loss: 0.5115 - val_accuracy: 0.0000e+00 - val_loss: 0.6289\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0456 - loss: 0.4766\n",
            "Epoch 10: val_loss did not improve from 0.61195\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0395 - loss: 0.4769 - val_accuracy: 0.0000e+00 - val_loss: 0.6313\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0020 - loss: 0.4671    \n",
            "Epoch 11: val_loss did not improve from 0.61195\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0036 - loss: 0.4630 - val_accuracy: 0.0000e+00 - val_loss: 0.6274\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0176 - loss: 0.4544    \n",
            "Epoch 12: val_loss did not improve from 0.61195\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0209 - loss: 0.4509 - val_accuracy: 0.0000e+00 - val_loss: 0.6261\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0410 - loss: 0.4269\n",
            "Epoch 13: val_loss did not improve from 0.61195\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0342 - loss: 0.4282 - val_accuracy: 0.0000e+00 - val_loss: 0.6348\n",
            "Epoch 14/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0189 - loss: 0.4485    \n",
            "Epoch 14: val_loss did not improve from 0.61195\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0240 - loss: 0.4370 - val_accuracy: 0.0000e+00 - val_loss: 0.6303\n",
            "\n",
            "  Completed 14 epochs (early stopped: True)\n",
            "  Final training loss: 0.4141\n",
            "  Final validation loss: 0.6303\n",
            "  Best validation loss: 0.6120\n",
            "\n",
            "  FOLD 3 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.5988\n",
            "    Recall:        0.9375\n",
            "    F1 Score:      0.6899\n",
            "    Hamming Loss:  0.4071\n",
            "    Hamming Accuracy:     0.5929\n",
            "    F1 Macro:             0.7023\n",
            "    F1 Micro:             0.7336\n",
            "    Jaccard (samples):    0.5709\n",
            "\n",
            "  FOLD 4/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1185 - loss: 0.6901\n",
            "Epoch 1: val_loss improved from inf to 0.67409, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 193ms/step - accuracy: 0.1126 - loss: 0.6887 - val_accuracy: 0.1500 - val_loss: 0.6741\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1009 - loss: 0.6620\n",
            "Epoch 2: val_loss improved from 0.67409 to 0.65441, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0874 - loss: 0.6611 - val_accuracy: 0.2000 - val_loss: 0.6544\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0983 - loss: 0.6305\n",
            "Epoch 3: val_loss improved from 0.65441 to 0.65015, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0969 - loss: 0.6300 - val_accuracy: 0.2000 - val_loss: 0.6501\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0345 - loss: 0.6124\n",
            "Epoch 4: val_loss improved from 0.65015 to 0.64707, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0409 - loss: 0.6156 - val_accuracy: 0.2000 - val_loss: 0.6471\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0625 - loss: 0.6153\n",
            "Epoch 5: val_loss improved from 0.64707 to 0.63761, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0618 - loss: 0.6152 - val_accuracy: 0.2000 - val_loss: 0.6376\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0378 - loss: 0.6264\n",
            "Epoch 6: val_loss improved from 0.63761 to 0.63115, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0364 - loss: 0.6188 - val_accuracy: 0.2000 - val_loss: 0.6311\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0436 - loss: 0.5971\n",
            "Epoch 7: val_loss improved from 0.63115 to 0.63070, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0470 - loss: 0.5965 - val_accuracy: 0.2000 - val_loss: 0.6307\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0332 - loss: 0.5624\n",
            "Epoch 8: val_loss did not improve from 0.63070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0333 - loss: 0.5636 - val_accuracy: 0.2000 - val_loss: 0.6372\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0397 - loss: 0.5360\n",
            "Epoch 9: val_loss did not improve from 0.63070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0399 - loss: 0.5370 - val_accuracy: 0.2000 - val_loss: 0.6459\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0215 - loss: 0.5367    \n",
            "Epoch 10: val_loss did not improve from 0.63070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0255 - loss: 0.5313 - val_accuracy: 0.2000 - val_loss: 0.7030\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0495 - loss: 0.5125\n",
            "Epoch 11: val_loss did not improve from 0.63070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0442 - loss: 0.5088 - val_accuracy: 0.2000 - val_loss: 0.7251\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0085 - loss: 0.4981    \n",
            "Epoch 12: val_loss did not improve from 0.63070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0101 - loss: 0.4948 - val_accuracy: 0.2000 - val_loss: 0.7376\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0000e+00 - loss: 0.4768\n",
            "Epoch 13: val_loss did not improve from 0.63070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0000e+00 - loss: 0.4736 - val_accuracy: 0.2000 - val_loss: 0.7068\n",
            "\n",
            "  Completed 13 epochs (early stopped: True)\n",
            "  Final training loss: 0.4670\n",
            "  Final validation loss: 0.7068\n",
            "  Best validation loss: 0.6307\n",
            "\n",
            "  FOLD 4 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.6397\n",
            "    Recall:        0.9386\n",
            "    F1 Score:      0.7009\n",
            "    Hamming Loss:  0.3750\n",
            "    Hamming Accuracy:     0.6250\n",
            "    F1 Macro:             0.6945\n",
            "    F1 Micro:             0.7518\n",
            "    Jaccard (samples):    0.5956\n",
            "\n",
            "  FOLD 5/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0215 - loss: 0.6919   \n",
            "Epoch 1: val_loss improved from inf to 0.68258, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step - accuracy: 0.0214 - loss: 0.6909 - val_accuracy: 0.1500 - val_loss: 0.6826\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0410 - loss: 0.6746\n",
            "Epoch 2: val_loss improved from 0.68258 to 0.66458, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0438 - loss: 0.6720 - val_accuracy: 0.0000e+00 - val_loss: 0.6646\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0397 - loss: 0.6371\n",
            "Epoch 3: val_loss did not improve from 0.66458\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0406 - loss: 0.6349 - val_accuracy: 0.1500 - val_loss: 0.6680\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0632 - loss: 0.6099\n",
            "Epoch 4: val_loss did not improve from 0.66458\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0726 - loss: 0.6092 - val_accuracy: 0.1500 - val_loss: 0.6735\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0820 - loss: 0.6000\n",
            "Epoch 5: val_loss improved from 0.66458 to 0.66081, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0758 - loss: 0.6009 - val_accuracy: 0.0000e+00 - val_loss: 0.6608\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0280 - loss: 0.5783    \n",
            "Epoch 6: val_loss improved from 0.66081 to 0.64900, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.0304 - loss: 0.5824 - val_accuracy: 0.0000e+00 - val_loss: 0.6490\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0430 - loss: 0.5722\n",
            "Epoch 7: val_loss improved from 0.64900 to 0.64688, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0380 - loss: 0.5746 - val_accuracy: 0.0000e+00 - val_loss: 0.6469\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0332 - loss: 0.5601\n",
            "Epoch 8: val_loss did not improve from 0.64688\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0292 - loss: 0.5596 - val_accuracy: 0.0000e+00 - val_loss: 0.6498\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0202 - loss: 0.5279\n",
            "Epoch 9: val_loss did not improve from 0.64688\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0205 - loss: 0.5255 - val_accuracy: 0.0000e+00 - val_loss: 0.6995\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0417 - loss: 0.5012\n",
            "Epoch 10: val_loss improved from 0.64688 to 0.64447, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0466 - loss: 0.4995 - val_accuracy: 0.1500 - val_loss: 0.6445\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0605 - loss: 0.4758\n",
            "Epoch 11: val_loss did not improve from 0.64447\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0615 - loss: 0.4774 - val_accuracy: 0.1000 - val_loss: 0.7430\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0566 - loss: 0.4783\n",
            "Epoch 12: val_loss did not improve from 0.64447\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0612 - loss: 0.4730 - val_accuracy: 0.1500 - val_loss: 0.6883\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0703 - loss: 0.4555\n",
            "Epoch 13: val_loss did not improve from 0.64447\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0680 - loss: 0.4532 - val_accuracy: 0.1500 - val_loss: 0.6673\n",
            "Epoch 14/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1003 - loss: 0.4324\n",
            "Epoch 14: val_loss did not improve from 0.64447\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0974 - loss: 0.4306 - val_accuracy: 0.1500 - val_loss: 0.6797\n",
            "Epoch 15/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1224 - loss: 0.4103\n",
            "Epoch 15: val_loss did not improve from 0.64447\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1168 - loss: 0.4125 - val_accuracy: 0.1500 - val_loss: 0.7768\n",
            "Epoch 16/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1393 - loss: 0.3960\n",
            "Epoch 16: val_loss did not improve from 0.64447\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1257 - loss: 0.3952 - val_accuracy: 0.1500 - val_loss: 0.7418\n",
            "\n",
            "  Completed 16 epochs (early stopped: False)\n",
            "  Final training loss: 0.3936\n",
            "  Final validation loss: 0.7418\n",
            "  Best validation loss: 0.6445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x798964178360> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  FOLD 5 RESULTS:\n",
            "    Accuracy:      0.0500\n",
            "    Precision:     0.5640\n",
            "    Recall:        0.9154\n",
            "    F1 Score:      0.6540\n",
            "    Hamming Loss:  0.4500\n",
            "    Hamming Accuracy:     0.5500\n",
            "    F1 Macro:             0.6347\n",
            "    F1 Micro:             0.6881\n",
            "    Jaccard (samples):    0.5189\n",
            "\n",
            "================================================================================\n",
            "COMBINATION 1 SUMMARY\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.3, 'lstm_units': 64}\n",
            "Average Accuracy:      0.0500 (+/- 0.0775)\n",
            "Average Precision:     0.6130 (+/- 0.0315)\n",
            "Average Recall:        0.9426 (+/- 0.0300)\n",
            "Average F1 Score:      0.6956 (+/- 0.0296)\n",
            "Average Hamming Loss:  0.3986 (+/- 0.0353)\n",
            "Average Hamming Accuracy: 0.6014\n",
            "Average F1 Macro:         0.6951\n",
            "Average F1 Micro:         0.7373\n",
            "Average Jaccard (samples):0.5804\n",
            "Completed at: 19:38:53\n",
            "\n",
            "âœ“ Results saved to /content/drive/MyDrive/lstm_keywords/results_1/grid_search_results.json\n",
            "\n",
            "================================================================================\n",
            "COMBINATION 2/4\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.3, 'lstm_units': 128}\n",
            "Started at: 19:38:53\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  FOLD 1/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0996 - loss: 0.6894\n",
            "Epoch 1: val_loss improved from inf to 0.66025, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 206ms/step - accuracy: 0.0969 - loss: 0.6873 - val_accuracy: 0.0000e+00 - val_loss: 0.6603\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1556 - loss: 0.6399\n",
            "Epoch 2: val_loss improved from 0.66025 to 0.63379, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1389 - loss: 0.6373 - val_accuracy: 0.0000e+00 - val_loss: 0.6338\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0436 - loss: 0.6007\n",
            "Epoch 3: val_loss improved from 0.63379 to 0.62316, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0408 - loss: 0.6039 - val_accuracy: 0.0000e+00 - val_loss: 0.6232\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0182 - loss: 0.6028\n",
            "Epoch 4: val_loss improved from 0.62316 to 0.61728, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0168 - loss: 0.6010 - val_accuracy: 0.0000e+00 - val_loss: 0.6173\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0046 - loss: 0.5912    \n",
            "Epoch 5: val_loss improved from 0.61728 to 0.61484, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0054 - loss: 0.5901 - val_accuracy: 0.0000e+00 - val_loss: 0.6148\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0267 - loss: 0.5646\n",
            "Epoch 6: val_loss did not improve from 0.61484\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0248 - loss: 0.5696 - val_accuracy: 0.0000e+00 - val_loss: 0.6184\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0286 - loss: 0.5744\n",
            "Epoch 7: val_loss did not improve from 0.61484\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0308 - loss: 0.5708 - val_accuracy: 0.0500 - val_loss: 0.6188\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0208 - loss: 0.5340    \n",
            "Epoch 8: val_loss did not improve from 0.61484\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0280 - loss: 0.5357 - val_accuracy: 0.0500 - val_loss: 0.6531\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0215 - loss: 0.4931    \n",
            "Epoch 9: val_loss did not improve from 0.61484\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0308 - loss: 0.4955 - val_accuracy: 0.0000e+00 - val_loss: 0.6211\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0189 - loss: 0.4887    \n",
            "Epoch 10: val_loss did not improve from 0.61484\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0220 - loss: 0.4867 - val_accuracy: 0.0500 - val_loss: 0.6447\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0065 - loss: 0.4593    \n",
            "Epoch 11: val_loss did not improve from 0.61484\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0090 - loss: 0.4578 - val_accuracy: 0.1000 - val_loss: 0.7967\n",
            "\n",
            "  Completed 11 epochs (early stopped: True)\n",
            "  Final training loss: 0.4547\n",
            "  Final validation loss: 0.7967\n",
            "  Best validation loss: 0.6148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x79899c2a9c60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  FOLD 1 RESULTS:\n",
            "    Accuracy:      0.1000\n",
            "    Precision:     0.5964\n",
            "    Recall:        1.0000\n",
            "    F1 Score:      0.7070\n",
            "    Hamming Loss:  0.4036\n",
            "    Hamming Accuracy:     0.5964\n",
            "    F1 Macro:             0.7320\n",
            "    F1 Micro:             0.7472\n",
            "    Jaccard (samples):    0.5964\n",
            "\n",
            "  FOLD 2/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0371 - loss: 0.6913\n",
            "Epoch 1: val_loss improved from inf to 0.66474, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.0339 - loss: 0.6900 - val_accuracy: 0.0000e+00 - val_loss: 0.6647\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0247 - loss: 0.6585\n",
            "Epoch 2: val_loss improved from 0.66474 to 0.61557, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0256 - loss: 0.6553 - val_accuracy: 0.0000e+00 - val_loss: 0.6156\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0046 - loss: 0.6156    \n",
            "Epoch 3: val_loss improved from 0.61557 to 0.60276, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0053 - loss: 0.6162 - val_accuracy: 0.0000e+00 - val_loss: 0.6028\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 0.5969\n",
            "Epoch 4: val_loss improved from 0.60276 to 0.59877, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0000e+00 - loss: 0.5975 - val_accuracy: 0.0000e+00 - val_loss: 0.5988\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0508 - loss: 0.6027\n",
            "Epoch 5: val_loss improved from 0.59877 to 0.59718, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0453 - loss: 0.6067 - val_accuracy: 0.0000e+00 - val_loss: 0.5972\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 0.6066\n",
            "Epoch 6: val_loss improved from 0.59718 to 0.59697, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.0300 - loss: 0.6019 - val_accuracy: 0.0000e+00 - val_loss: 0.5970\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0182 - loss: 0.5783\n",
            "Epoch 7: val_loss did not improve from 0.59697\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0167 - loss: 0.5794 - val_accuracy: 0.0000e+00 - val_loss: 0.6007\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0202 - loss: 0.5523\n",
            "Epoch 8: val_loss did not improve from 0.59697\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0203 - loss: 0.5563 - val_accuracy: 0.0000e+00 - val_loss: 0.6090\n",
            "Epoch 9/30\n",
            "\u001b[1m3/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0347 - loss: 0.5421\n",
            "Epoch 9: val_loss did not improve from 0.59697\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0470 - loss: 0.5377 - val_accuracy: 0.1000 - val_loss: 0.6327\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0801 - loss: 0.5028\n",
            "Epoch 10: val_loss did not improve from 0.59697\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0717 - loss: 0.4994 - val_accuracy: 0.1000 - val_loss: 0.6684\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0618 - loss: 0.5055\n",
            "Epoch 11: val_loss did not improve from 0.59697\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0663 - loss: 0.4983 - val_accuracy: 0.0500 - val_loss: 0.7043\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1185 - loss: 0.4450\n",
            "Epoch 12: val_loss did not improve from 0.59697\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1087 - loss: 0.4508 - val_accuracy: 0.1000 - val_loss: 0.7041\n",
            "\n",
            "  Completed 12 epochs (early stopped: True)\n",
            "  Final training loss: 0.4624\n",
            "  Final validation loss: 0.7041\n",
            "  Best validation loss: 0.5970\n",
            "\n",
            "  FOLD 2 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.6602\n",
            "    Recall:        0.9534\n",
            "    F1 Score:      0.7329\n",
            "    Hamming Loss:  0.3571\n",
            "    Hamming Accuracy:     0.6429\n",
            "    F1 Macro:             0.7296\n",
            "    F1 Micro:             0.7748\n",
            "    Jaccard (samples):    0.6266\n",
            "\n",
            "  FOLD 3/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0189 - loss: 0.6901   \n",
            "Epoch 1: val_loss improved from inf to 0.65762, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 196ms/step - accuracy: 0.0194 - loss: 0.6882 - val_accuracy: 0.1000 - val_loss: 0.6576\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0417 - loss: 0.6531\n",
            "Epoch 2: val_loss improved from 0.65762 to 0.62766, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0392 - loss: 0.6490 - val_accuracy: 0.0000e+00 - val_loss: 0.6277\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0085 - loss: 0.6263    \n",
            "Epoch 3: val_loss improved from 0.62766 to 0.62051, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0079 - loss: 0.6244 - val_accuracy: 0.0000e+00 - val_loss: 0.6205\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0169 - loss: 0.6089    \n",
            "Epoch 4: val_loss did not improve from 0.62051\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0227 - loss: 0.6086 - val_accuracy: 0.0000e+00 - val_loss: 0.6206\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0579 - loss: 0.5998\n",
            "Epoch 5: val_loss did not improve from 0.62051\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0523 - loss: 0.5978 - val_accuracy: 0.0000e+00 - val_loss: 0.6222\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0384 - loss: 0.5856\n",
            "Epoch 6: val_loss did not improve from 0.62051\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0370 - loss: 0.5834 - val_accuracy: 0.0000e+00 - val_loss: 0.6347\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0046 - loss: 0.5765    \n",
            "Epoch 7: val_loss did not improve from 0.62051\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0053 - loss: 0.5749 - val_accuracy: 0.0000e+00 - val_loss: 0.6474\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0020 - loss: 0.5355    \n",
            "Epoch 8: val_loss did not improve from 0.62051\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0059 - loss: 0.5364 - val_accuracy: 0.0000e+00 - val_loss: 0.6738\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0898 - loss: 0.5106\n",
            "Epoch 9: val_loss did not improve from 0.62051\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0827 - loss: 0.5062 - val_accuracy: 0.0500 - val_loss: 0.6811\n",
            "\n",
            "  Completed 9 epochs (early stopped: True)\n",
            "  Final training loss: 0.4974\n",
            "  Final validation loss: 0.6811\n",
            "  Best validation loss: 0.6205\n",
            "\n",
            "  FOLD 3 RESULTS:\n",
            "    Accuracy:      0.0500\n",
            "    Precision:     0.6292\n",
            "    Recall:        0.9067\n",
            "    F1 Score:      0.6967\n",
            "    Hamming Loss:  0.3786\n",
            "    Hamming Accuracy:     0.6214\n",
            "    F1 Macro:             0.6515\n",
            "    F1 Micro:             0.7402\n",
            "    Jaccard (samples):    0.5850\n",
            "\n",
            "  FOLD 4/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0085 - loss: 0.6876   \n",
            "Epoch 1: val_loss improved from inf to 0.66750, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - accuracy: 0.0101 - loss: 0.6854 - val_accuracy: 0.0000e+00 - val_loss: 0.6675\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0358 - loss: 0.6472\n",
            "Epoch 2: val_loss improved from 0.66750 to 0.65509, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0351 - loss: 0.6473 - val_accuracy: 0.0000e+00 - val_loss: 0.6551\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0085 - loss: 0.6247    \n",
            "Epoch 3: val_loss improved from 0.65509 to 0.63755, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0101 - loss: 0.6205 - val_accuracy: 0.0000e+00 - val_loss: 0.6375\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0293 - loss: 0.5999\n",
            "Epoch 4: val_loss improved from 0.63755 to 0.63176, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0330 - loss: 0.5988 - val_accuracy: 0.2000 - val_loss: 0.6318\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0423 - loss: 0.5906\n",
            "Epoch 5: val_loss improved from 0.63176 to 0.62878, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0394 - loss: 0.5911 - val_accuracy: 0.2000 - val_loss: 0.6288\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0247 - loss: 0.5686\n",
            "Epoch 6: val_loss did not improve from 0.62878\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0277 - loss: 0.5705 - val_accuracy: 0.2000 - val_loss: 0.6295\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0254 - loss: 0.5423\n",
            "Epoch 7: val_loss did not improve from 0.62878\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0236 - loss: 0.5389 - val_accuracy: 0.2000 - val_loss: 0.6491\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0254 - loss: 0.4852    \n",
            "Epoch 8: val_loss did not improve from 0.62878\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0281 - loss: 0.4874 - val_accuracy: 0.1500 - val_loss: 0.7120\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0645 - loss: 0.4739\n",
            "Epoch 9: val_loss did not improve from 0.62878\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0698 - loss: 0.4725 - val_accuracy: 0.1000 - val_loss: 0.7201\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0339 - loss: 0.4457\n",
            "Epoch 10: val_loss did not improve from 0.62878\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0382 - loss: 0.4489 - val_accuracy: 0.2000 - val_loss: 0.7767\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0449 - loss: 0.4387    \n",
            "Epoch 11: val_loss did not improve from 0.62878\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0501 - loss: 0.4402 - val_accuracy: 0.2000 - val_loss: 0.7300\n",
            "\n",
            "  Completed 11 epochs (early stopped: True)\n",
            "  Final training loss: 0.4432\n",
            "  Final validation loss: 0.7300\n",
            "  Best validation loss: 0.6288\n",
            "\n",
            "  FOLD 4 RESULTS:\n",
            "    Accuracy:      0.1500\n",
            "    Precision:     0.6223\n",
            "    Recall:        0.9902\n",
            "    F1 Score:      0.7089\n",
            "    Hamming Loss:  0.3786\n",
            "    Hamming Accuracy:     0.6214\n",
            "    F1 Macro:             0.7489\n",
            "    F1 Micro:             0.7634\n",
            "    Jaccard (samples):    0.6168\n",
            "\n",
            "  FOLD 5/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0273 - loss: 0.6918\n",
            "Epoch 1: val_loss improved from inf to 0.67480, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 200ms/step - accuracy: 0.0323 - loss: 0.6907 - val_accuracy: 0.0000e+00 - val_loss: 0.6748\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0326 - loss: 0.6641\n",
            "Epoch 2: val_loss improved from 0.67480 to 0.63693, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0358 - loss: 0.6630 - val_accuracy: 0.0500 - val_loss: 0.6369\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0618 - loss: 0.6291\n",
            "Epoch 3: val_loss did not improve from 0.63693\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0647 - loss: 0.6266 - val_accuracy: 0.1500 - val_loss: 0.6381\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0788 - loss: 0.6185\n",
            "Epoch 4: val_loss improved from 0.63693 to 0.62959, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.3_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0760 - loss: 0.6180 - val_accuracy: 0.1500 - val_loss: 0.6296\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0898 - loss: 0.6058\n",
            "Epoch 5: val_loss did not improve from 0.62959\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0881 - loss: 0.6051 - val_accuracy: 0.1500 - val_loss: 0.6329\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0573 - loss: 0.6020\n",
            "Epoch 6: val_loss did not improve from 0.62959\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0570 - loss: 0.6024 - val_accuracy: 0.1500 - val_loss: 0.6444\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0527 - loss: 0.5678\n",
            "Epoch 7: val_loss did not improve from 0.62959\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0516 - loss: 0.5718 - val_accuracy: 0.1500 - val_loss: 0.6451\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0579 - loss: 0.5589\n",
            "Epoch 8: val_loss did not improve from 0.62959\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0598 - loss: 0.5598 - val_accuracy: 0.1500 - val_loss: 0.6379\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0911 - loss: 0.5555\n",
            "Epoch 9: val_loss did not improve from 0.62959\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0889 - loss: 0.5535 - val_accuracy: 0.1500 - val_loss: 0.6573\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0853 - loss: 0.5152\n",
            "Epoch 10: val_loss did not improve from 0.62959\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0850 - loss: 0.5127 - val_accuracy: 0.1500 - val_loss: 0.7166\n",
            "\n",
            "  Completed 10 epochs (early stopped: True)\n",
            "  Final training loss: 0.5078\n",
            "  Final validation loss: 0.7166\n",
            "  Best validation loss: 0.6296\n",
            "\n",
            "  FOLD 5 RESULTS:\n",
            "    Accuracy:      0.0500\n",
            "    Precision:     0.5853\n",
            "    Recall:        0.9488\n",
            "    F1 Score:      0.6833\n",
            "    Hamming Loss:  0.4071\n",
            "    Hamming Accuracy:     0.5929\n",
            "    F1 Macro:             0.6509\n",
            "    F1 Micro:             0.7178\n",
            "    Jaccard (samples):    0.5541\n",
            "\n",
            "================================================================================\n",
            "COMBINATION 2 SUMMARY\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.3, 'lstm_units': 128}\n",
            "Average Accuracy:      0.0700 (+/- 0.0510)\n",
            "Average Precision:     0.6187 (+/- 0.0263)\n",
            "Average Recall:        0.9598 (+/- 0.0332)\n",
            "Average F1 Score:      0.7058 (+/- 0.0164)\n",
            "Average Hamming Loss:  0.3850 (+/- 0.0184)\n",
            "Average Hamming Accuracy: 0.6150\n",
            "Average F1 Macro:         0.7025\n",
            "Average F1 Micro:         0.7487\n",
            "Average Jaccard (samples):0.5958\n",
            "Completed at: 19:39:33\n",
            "\n",
            "âœ“ Results saved to /content/drive/MyDrive/lstm_keywords/results_1/grid_search_results.json\n",
            "\n",
            "================================================================================\n",
            "COMBINATION 3/4\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.5, 'lstm_units': 64}\n",
            "Started at: 19:39:33\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  FOLD 1/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0918 - loss: 0.6922\n",
            "Epoch 1: val_loss improved from inf to 0.68537, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 192ms/step - accuracy: 0.0894 - loss: 0.6918 - val_accuracy: 0.0000e+00 - val_loss: 0.6854\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0768 - loss: 0.6797\n",
            "Epoch 2: val_loss improved from 0.68537 to 0.67033, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.0841 - loss: 0.6785 - val_accuracy: 0.0000e+00 - val_loss: 0.6703\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0618 - loss: 0.6629\n",
            "Epoch 3: val_loss improved from 0.67033 to 0.65250, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0624 - loss: 0.6601 - val_accuracy: 0.0000e+00 - val_loss: 0.6525\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1217 - loss: 0.6352\n",
            "Epoch 4: val_loss improved from 0.65250 to 0.64348, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.1140 - loss: 0.6368 - val_accuracy: 0.0000e+00 - val_loss: 0.6435\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0872 - loss: 0.6258\n",
            "Epoch 5: val_loss improved from 0.64348 to 0.63115, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0887 - loss: 0.6228 - val_accuracy: 0.0000e+00 - val_loss: 0.6311\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0495 - loss: 0.6157    \n",
            "Epoch 6: val_loss improved from 0.63115 to 0.62600, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.0518 - loss: 0.6142 - val_accuracy: 0.0000e+00 - val_loss: 0.6260\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0423 - loss: 0.6207\n",
            "Epoch 7: val_loss improved from 0.62600 to 0.62376, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0423 - loss: 0.6181 - val_accuracy: 0.0000e+00 - val_loss: 0.6238\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0684 - loss: 0.5865\n",
            "Epoch 8: val_loss did not improve from 0.62376\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0714 - loss: 0.5883 - val_accuracy: 0.0000e+00 - val_loss: 0.6313\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0508 - loss: 0.5913\n",
            "Epoch 9: val_loss did not improve from 0.62376\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0526 - loss: 0.5860 - val_accuracy: 0.0000e+00 - val_loss: 0.6445\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1068 - loss: 0.5303\n",
            "Epoch 10: val_loss did not improve from 0.62376\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1064 - loss: 0.5397 - val_accuracy: 0.0000e+00 - val_loss: 0.7362\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0814 - loss: 0.7045\n",
            "Epoch 11: val_loss did not improve from 0.62376\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0801 - loss: 0.7013 - val_accuracy: 0.0000e+00 - val_loss: 0.6764\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0475 - loss: 0.6477\n",
            "Epoch 12: val_loss did not improve from 0.62376\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0458 - loss: 0.6472 - val_accuracy: 0.0000e+00 - val_loss: 0.6306\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0605 - loss: 0.6287\n",
            "Epoch 13: val_loss improved from 0.62376 to 0.62360, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0591 - loss: 0.6265 - val_accuracy: 0.1500 - val_loss: 0.6236\n",
            "Epoch 14/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0742 - loss: 0.6105\n",
            "Epoch 14: val_loss did not improve from 0.62360\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0706 - loss: 0.6087 - val_accuracy: 0.0000e+00 - val_loss: 0.6256\n",
            "Epoch 15/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0456 - loss: 0.5952\n",
            "Epoch 15: val_loss did not improve from 0.62360\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0398 - loss: 0.5923 - val_accuracy: 0.0000e+00 - val_loss: 0.6298\n",
            "Epoch 16/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0332 - loss: 0.5617\n",
            "Epoch 16: val_loss improved from 0.62360 to 0.62349, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.0339 - loss: 0.5611 - val_accuracy: 0.0000e+00 - val_loss: 0.6235\n",
            "Epoch 17/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0469 - loss: 0.5524\n",
            "Epoch 17: val_loss did not improve from 0.62349\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0453 - loss: 0.5529 - val_accuracy: 0.0000e+00 - val_loss: 0.6267\n",
            "Epoch 18/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0332 - loss: 0.5336\n",
            "Epoch 18: val_loss did not improve from 0.62349\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0362 - loss: 0.5324 - val_accuracy: 0.0000e+00 - val_loss: 0.6298\n",
            "Epoch 19/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0456 - loss: 0.5099\n",
            "Epoch 19: val_loss did not improve from 0.62349\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0515 - loss: 0.5086 - val_accuracy: 0.0000e+00 - val_loss: 0.6300\n",
            "Epoch 20/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1276 - loss: 0.4956\n",
            "Epoch 20: val_loss did not improve from 0.62349\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1156 - loss: 0.4940 - val_accuracy: 0.0000e+00 - val_loss: 0.6379\n",
            "Epoch 21/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0566 - loss: 0.4714\n",
            "Epoch 21: val_loss did not improve from 0.62349\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0589 - loss: 0.4721 - val_accuracy: 0.0000e+00 - val_loss: 0.6462\n",
            "Epoch 22/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0560 - loss: 0.4745\n",
            "Epoch 22: val_loss did not improve from 0.62349\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0538 - loss: 0.4704 - val_accuracy: 0.0000e+00 - val_loss: 0.6542\n",
            "\n",
            "  Completed 22 epochs (early stopped: False)\n",
            "  Final training loss: 0.4621\n",
            "  Final validation loss: 0.6542\n",
            "  Best validation loss: 0.6235\n",
            "\n",
            "  FOLD 1 RESULTS:\n",
            "    Accuracy:      0.0500\n",
            "    Precision:     0.5981\n",
            "    Recall:        0.9880\n",
            "    F1 Score:      0.7026\n",
            "    Hamming Loss:  0.4107\n",
            "    Hamming Accuracy:     0.5893\n",
            "    F1 Macro:             0.7219\n",
            "    F1 Micro:             0.7404\n",
            "    Jaccard (samples):    0.5885\n",
            "\n",
            "  FOLD 2/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0820 - loss: 0.6928\n",
            "Epoch 1: val_loss improved from inf to 0.68386, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 199ms/step - accuracy: 0.0775 - loss: 0.6921 - val_accuracy: 0.0000e+00 - val_loss: 0.6839\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0573 - loss: 0.6790\n",
            "Epoch 2: val_loss improved from 0.68386 to 0.66322, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0633 - loss: 0.6782 - val_accuracy: 0.0000e+00 - val_loss: 0.6632\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1224 - loss: 0.6549\n",
            "Epoch 3: val_loss improved from 0.66322 to 0.63961, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.1273 - loss: 0.6549 - val_accuracy: 0.1500 - val_loss: 0.6396\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0768 - loss: 0.6288\n",
            "Epoch 4: val_loss improved from 0.63961 to 0.62236, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0786 - loss: 0.6317 - val_accuracy: 0.1500 - val_loss: 0.6224\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1322 - loss: 0.6568\n",
            "Epoch 5: val_loss improved from 0.62236 to 0.61540, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.1178 - loss: 0.6518 - val_accuracy: 0.1500 - val_loss: 0.6154\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0638 - loss: 0.6189\n",
            "Epoch 6: val_loss improved from 0.61540 to 0.60943, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0631 - loss: 0.6175 - val_accuracy: 0.1500 - val_loss: 0.6094\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0579 - loss: 0.6141\n",
            "Epoch 7: val_loss improved from 0.60943 to 0.60632, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0546 - loss: 0.6103 - val_accuracy: 0.1500 - val_loss: 0.6063\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0788 - loss: 0.5492\n",
            "Epoch 8: val_loss did not improve from 0.60632\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0753 - loss: 0.5573 - val_accuracy: 0.1500 - val_loss: 0.6090\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0195 - loss: 0.5494    \n",
            "Epoch 9: val_loss did not improve from 0.60632\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0222 - loss: 0.5505 - val_accuracy: 0.1000 - val_loss: 0.6162\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0872 - loss: 0.5363\n",
            "Epoch 10: val_loss did not improve from 0.60632\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0901 - loss: 0.5359 - val_accuracy: 0.1000 - val_loss: 0.6397\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0312 - loss: 0.5351\n",
            "Epoch 11: val_loss did not improve from 0.60632\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0322 - loss: 0.5311 - val_accuracy: 0.1000 - val_loss: 0.6454\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1009 - loss: 0.5248\n",
            "Epoch 12: val_loss did not improve from 0.60632\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1015 - loss: 0.5193 - val_accuracy: 0.1000 - val_loss: 0.6514\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0697 - loss: 0.5101\n",
            "Epoch 13: val_loss did not improve from 0.60632\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0738 - loss: 0.5066 - val_accuracy: 0.1000 - val_loss: 0.6517\n",
            "\n",
            "  Completed 13 epochs (early stopped: True)\n",
            "  Final training loss: 0.4996\n",
            "  Final validation loss: 0.6517\n",
            "  Best validation loss: 0.6063\n",
            "\n",
            "  FOLD 2 RESULTS:\n",
            "    Accuracy:      0.0500\n",
            "    Precision:     0.6607\n",
            "    Recall:        0.9612\n",
            "    F1 Score:      0.7369\n",
            "    Hamming Loss:  0.3500\n",
            "    Hamming Accuracy:     0.6500\n",
            "    F1 Macro:             0.7500\n",
            "    F1 Micro:             0.7803\n",
            "    Jaccard (samples):    0.6338\n",
            "\n",
            "  FOLD 3/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 0.6915\n",
            "Epoch 1: val_loss improved from inf to 0.68020, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 197ms/step - accuracy: 0.0300 - loss: 0.6909 - val_accuracy: 0.0000e+00 - val_loss: 0.6802\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0104 - loss: 0.6821    \n",
            "Epoch 2: val_loss improved from 0.68020 to 0.66710, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0115 - loss: 0.6816 - val_accuracy: 0.0000e+00 - val_loss: 0.6671\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0104 - loss: 0.6643    \n",
            "Epoch 3: val_loss improved from 0.66710 to 0.65289, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0184 - loss: 0.6620 - val_accuracy: 0.0500 - val_loss: 0.6529\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0586 - loss: 0.6538\n",
            "Epoch 4: val_loss improved from 0.65289 to 0.64187, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0528 - loss: 0.6531 - val_accuracy: 0.0500 - val_loss: 0.6419\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 0.6322\n",
            "Epoch 5: val_loss improved from 0.64187 to 0.63485, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0322 - loss: 0.6325 - val_accuracy: 0.1500 - val_loss: 0.6349\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1009 - loss: 0.6358\n",
            "Epoch 6: val_loss improved from 0.63485 to 0.63094, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.1038 - loss: 0.6336 - val_accuracy: 0.1500 - val_loss: 0.6309\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0397 - loss: 0.6157\n",
            "Epoch 7: val_loss improved from 0.63094 to 0.62685, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0402 - loss: 0.6149 - val_accuracy: 0.1500 - val_loss: 0.6269\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0508 - loss: 0.6148\n",
            "Epoch 8: val_loss did not improve from 0.62685\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0498 - loss: 0.6103 - val_accuracy: 0.1500 - val_loss: 0.6272\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0397 - loss: 0.6076\n",
            "Epoch 9: val_loss did not improve from 0.62685\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0447 - loss: 0.6049 - val_accuracy: 0.1500 - val_loss: 0.6294\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0462 - loss: 0.5793\n",
            "Epoch 10: val_loss did not improve from 0.62685\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0514 - loss: 0.5813 - val_accuracy: 0.0500 - val_loss: 0.6328\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0540 - loss: 0.5753\n",
            "Epoch 11: val_loss improved from 0.62685 to 0.62563, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0520 - loss: 0.5753 - val_accuracy: 0.0500 - val_loss: 0.6256\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0254 - loss: 0.5336\n",
            "Epoch 12: val_loss improved from 0.62563 to 0.61465, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0238 - loss: 0.5325 - val_accuracy: 0.0500 - val_loss: 0.6147\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0391 - loss: 0.5223\n",
            "Epoch 13: val_loss did not improve from 0.61465\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0352 - loss: 0.5242 - val_accuracy: 0.0500 - val_loss: 0.6227\n",
            "Epoch 14/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0169 - loss: 0.4972    \n",
            "Epoch 14: val_loss did not improve from 0.61465\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0181 - loss: 0.5024 - val_accuracy: 0.0000e+00 - val_loss: 0.6275\n",
            "Epoch 15/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0410 - loss: 0.5006\n",
            "Epoch 15: val_loss did not improve from 0.61465\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0365 - loss: 0.5016 - val_accuracy: 0.0000e+00 - val_loss: 0.6218\n",
            "Epoch 16/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0280 - loss: 0.4717    \n",
            "Epoch 16: val_loss improved from 0.61465 to 0.59208, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0346 - loss: 0.4767 - val_accuracy: 0.1000 - val_loss: 0.5921\n",
            "Epoch 17/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0339 - loss: 0.4608    \n",
            "Epoch 17: val_loss did not improve from 0.59208\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0386 - loss: 0.4626 - val_accuracy: 0.1500 - val_loss: 0.6220\n",
            "Epoch 18/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0501 - loss: 0.4539\n",
            "Epoch 18: val_loss did not improve from 0.59208\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0540 - loss: 0.4576 - val_accuracy: 0.1000 - val_loss: 0.6136\n",
            "Epoch 19/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0710 - loss: 0.4403\n",
            "Epoch 19: val_loss did not improve from 0.59208\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0701 - loss: 0.4399 - val_accuracy: 0.1000 - val_loss: 0.6037\n",
            "Epoch 20/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0365 - loss: 0.4192\n",
            "Epoch 20: val_loss did not improve from 0.59208\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0357 - loss: 0.4227 - val_accuracy: 0.0000e+00 - val_loss: 0.6075\n",
            "Epoch 21/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0684 - loss: 0.4242\n",
            "Epoch 21: val_loss did not improve from 0.59208\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0753 - loss: 0.4303 - val_accuracy: 0.0000e+00 - val_loss: 0.6236\n",
            "Epoch 22/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0482 - loss: 0.3882\n",
            "Epoch 22: val_loss did not improve from 0.59208\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0504 - loss: 0.3974 - val_accuracy: 0.1000 - val_loss: 0.5957\n",
            "\n",
            "  Completed 22 epochs (early stopped: False)\n",
            "  Final training loss: 0.4159\n",
            "  Final validation loss: 0.5957\n",
            "  Best validation loss: 0.5921\n",
            "\n",
            "  FOLD 3 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.6098\n",
            "    Recall:        0.8916\n",
            "    F1 Score:      0.6820\n",
            "    Hamming Loss:  0.3893\n",
            "    Hamming Accuracy:     0.6107\n",
            "    F1 Macro:             0.7091\n",
            "    F1 Micro:             0.7335\n",
            "    Jaccard (samples):    0.5620\n",
            "\n",
            "  FOLD 4/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0879 - loss: 0.6897\n",
            "Epoch 1: val_loss improved from inf to 0.67485, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 317ms/step - accuracy: 0.0832 - loss: 0.6878 - val_accuracy: 0.2000 - val_loss: 0.6748\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0339 - loss: 0.6682\n",
            "Epoch 2: val_loss improved from 0.67485 to 0.65312, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.0382 - loss: 0.6662 - val_accuracy: 0.2000 - val_loss: 0.6531\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0938 - loss: 0.6506\n",
            "Epoch 3: val_loss improved from 0.65312 to 0.63757, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0893 - loss: 0.6490 - val_accuracy: 0.2000 - val_loss: 0.6376\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0534 - loss: 0.6358\n",
            "Epoch 4: val_loss improved from 0.63757 to 0.62642, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0557 - loss: 0.6361 - val_accuracy: 0.2000 - val_loss: 0.6264\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0964 - loss: 0.6286\n",
            "Epoch 5: val_loss improved from 0.62642 to 0.62190, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0844 - loss: 0.6276 - val_accuracy: 0.2000 - val_loss: 0.6219\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0332 - loss: 0.6182\n",
            "Epoch 6: val_loss improved from 0.62190 to 0.61957, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0400 - loss: 0.6172 - val_accuracy: 0.2000 - val_loss: 0.6196\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0938 - loss: 0.6156\n",
            "Epoch 7: val_loss did not improve from 0.61957\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0893 - loss: 0.6127 - val_accuracy: 0.2000 - val_loss: 0.6199\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0378 - loss: 0.5885\n",
            "Epoch 8: val_loss did not improve from 0.61957\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0498 - loss: 0.5918 - val_accuracy: 0.2000 - val_loss: 0.6235\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0710 - loss: 0.5798\n",
            "Epoch 9: val_loss did not improve from 0.61957\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0719 - loss: 0.5796 - val_accuracy: 0.2000 - val_loss: 0.6340\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0690 - loss: 0.5721\n",
            "Epoch 10: val_loss did not improve from 0.61957\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0617 - loss: 0.5665 - val_accuracy: 0.2000 - val_loss: 0.6497\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0905 - loss: 0.5254\n",
            "Epoch 11: val_loss did not improve from 0.61957\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0827 - loss: 0.5262 - val_accuracy: 0.2000 - val_loss: 0.6650\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0677 - loss: 0.5280\n",
            "Epoch 12: val_loss did not improve from 0.61957\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0675 - loss: 0.5231 - val_accuracy: 0.2000 - val_loss: 0.6680\n",
            "\n",
            "  Completed 12 epochs (early stopped: True)\n",
            "  Final training loss: 0.5133\n",
            "  Final validation loss: 0.6680\n",
            "  Best validation loss: 0.6196\n",
            "\n",
            "  FOLD 4 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.6283\n",
            "    Recall:        0.9573\n",
            "    F1 Score:      0.7016\n",
            "    Hamming Loss:  0.3786\n",
            "    Hamming Accuracy:     0.6214\n",
            "    F1 Macro:             0.7161\n",
            "    F1 Micro:             0.7558\n",
            "    Jaccard (samples):    0.6016\n",
            "\n",
            "  FOLD 5/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1224 - loss: 0.6889\n",
            "Epoch 1: val_loss improved from inf to 0.67269, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 195ms/step - accuracy: 0.1192 - loss: 0.6872 - val_accuracy: 0.1500 - val_loss: 0.6727\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0579 - loss: 0.6631\n",
            "Epoch 2: val_loss improved from 0.67269 to 0.65440, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0645 - loss: 0.6630 - val_accuracy: 0.1500 - val_loss: 0.6544\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0521 - loss: 0.6465\n",
            "Epoch 3: val_loss improved from 0.65440 to 0.64710, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.0488 - loss: 0.6463 - val_accuracy: 0.1500 - val_loss: 0.6471\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 0.6213\n",
            "Epoch 4: val_loss improved from 0.64710 to 0.64532, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.0367 - loss: 0.6255 - val_accuracy: 0.0000e+00 - val_loss: 0.6453\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0482 - loss: 0.6142\n",
            "Epoch 5: val_loss improved from 0.64532 to 0.63948, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0509 - loss: 0.6188 - val_accuracy: 0.0000e+00 - val_loss: 0.6395\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0566 - loss: 0.6052\n",
            "Epoch 6: val_loss improved from 0.63948 to 0.63527, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0565 - loss: 0.6071 - val_accuracy: 0.0000e+00 - val_loss: 0.6353\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0215 - loss: 0.6123    \n",
            "Epoch 7: val_loss did not improve from 0.63527\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0261 - loss: 0.6129 - val_accuracy: 0.0000e+00 - val_loss: 0.6373\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0273 - loss: 0.5915    \n",
            "Epoch 8: val_loss did not improve from 0.63527\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0347 - loss: 0.5919 - val_accuracy: 0.0000e+00 - val_loss: 0.6374\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0339 - loss: 0.5822\n",
            "Epoch 9: val_loss did not improve from 0.63527\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0343 - loss: 0.5820 - val_accuracy: 0.0500 - val_loss: 0.6395\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1055 - loss: 0.5446\n",
            "Epoch 10: val_loss did not improve from 0.63527\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0961 - loss: 0.5453 - val_accuracy: 0.1000 - val_loss: 0.6538\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0286 - loss: 0.5159    \n",
            "Epoch 11: val_loss did not improve from 0.63527\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0426 - loss: 0.5140 - val_accuracy: 0.0500 - val_loss: 0.6763\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.0671 - loss: 0.5134\n",
            "Epoch 12: val_loss improved from 0.63527 to 0.63193, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0705 - loss: 0.5118 - val_accuracy: 0.1500 - val_loss: 0.6319\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0579 - loss: 0.4735\n",
            "Epoch 13: val_loss improved from 0.63193 to 0.61863, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units64_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.0621 - loss: 0.4771 - val_accuracy: 0.1500 - val_loss: 0.6186\n",
            "Epoch 14/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0872 - loss: 0.4535\n",
            "Epoch 14: val_loss did not improve from 0.61863\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0887 - loss: 0.4593 - val_accuracy: 0.1500 - val_loss: 0.6393\n",
            "Epoch 15/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1204 - loss: 0.4431\n",
            "Epoch 15: val_loss did not improve from 0.61863\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.1061 - loss: 0.4490 - val_accuracy: 0.1000 - val_loss: 0.6554\n",
            "Epoch 16/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0540 - loss: 0.4287\n",
            "Epoch 16: val_loss did not improve from 0.61863\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.0642 - loss: 0.4293 - val_accuracy: 0.1500 - val_loss: 0.6283\n",
            "Epoch 17/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1172 - loss: 0.4636\n",
            "Epoch 17: val_loss did not improve from 0.61863\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1157 - loss: 0.4593 - val_accuracy: 0.1500 - val_loss: 0.6284\n",
            "Epoch 18/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0645 - loss: 0.4223    \n",
            "Epoch 18: val_loss did not improve from 0.61863\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0711 - loss: 0.4221 - val_accuracy: 0.1000 - val_loss: 0.6729\n",
            "Epoch 19/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1042 - loss: 0.4091\n",
            "Epoch 19: val_loss did not improve from 0.61863\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0976 - loss: 0.4074 - val_accuracy: 0.1000 - val_loss: 0.6754\n",
            "\n",
            "  Completed 19 epochs (early stopped: False)\n",
            "  Final training loss: 0.4039\n",
            "  Final validation loss: 0.6754\n",
            "  Best validation loss: 0.6186\n",
            "\n",
            "  FOLD 5 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.6125\n",
            "    Recall:        0.8338\n",
            "    F1 Score:      0.6571\n",
            "    Hamming Loss:  0.4000\n",
            "    Hamming Accuracy:     0.6000\n",
            "    F1 Macro:             0.5575\n",
            "    F1 Micro:             0.6872\n",
            "    Jaccard (samples):    0.5130\n",
            "\n",
            "================================================================================\n",
            "COMBINATION 3 SUMMARY\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.5, 'lstm_units': 64}\n",
            "Average Accuracy:      0.0200 (+/- 0.0245)\n",
            "Average Precision:     0.6219 (+/- 0.0217)\n",
            "Average Recall:        0.9264 (+/- 0.0561)\n",
            "Average F1 Score:      0.6960 (+/- 0.0263)\n",
            "Average Hamming Loss:  0.3857 (+/- 0.0208)\n",
            "Average Hamming Accuracy: 0.6143\n",
            "Average F1 Macro:         0.6909\n",
            "Average F1 Micro:         0.7394\n",
            "Average Jaccard (samples):0.5798\n",
            "Completed at: 19:40:21\n",
            "\n",
            "âœ“ Results saved to /content/drive/MyDrive/lstm_keywords/results_1/grid_search_results.json\n",
            "\n",
            "================================================================================\n",
            "COMBINATION 4/4\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.5, 'lstm_units': 128}\n",
            "Started at: 19:40:21\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "  FOLD 1/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0267 - loss: 0.6917\n",
            "Epoch 1: val_loss improved from inf to 0.67973, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 201ms/step - accuracy: 0.0272 - loss: 0.6912 - val_accuracy: 0.0000e+00 - val_loss: 0.6797\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0020 - loss: 0.6750    \n",
            "Epoch 2: val_loss improved from 0.67973 to 0.64244, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.0036 - loss: 0.6730 - val_accuracy: 0.0000e+00 - val_loss: 0.6424\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0417 - loss: 0.6482\n",
            "Epoch 3: val_loss improved from 0.64244 to 0.63172, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.0395 - loss: 0.6449 - val_accuracy: 0.0000e+00 - val_loss: 0.6317\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0332 - loss: 0.6242\n",
            "Epoch 4: val_loss did not improve from 0.63172\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0339 - loss: 0.6247 - val_accuracy: 0.0000e+00 - val_loss: 0.6327\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0130 - loss: 0.6374    \n",
            "Epoch 5: val_loss did not improve from 0.63172\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0157 - loss: 0.6363 - val_accuracy: 0.1000 - val_loss: 0.6317\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 0.6108\n",
            "Epoch 6: val_loss improved from 0.63172 to 0.62648, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0326 - loss: 0.6131 - val_accuracy: 0.1500 - val_loss: 0.6265\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0671 - loss: 0.6204\n",
            "Epoch 7: val_loss improved from 0.62648 to 0.62572, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold1.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0611 - loss: 0.6198 - val_accuracy: 0.1500 - val_loss: 0.6257\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 0.5965\n",
            "Epoch 8: val_loss did not improve from 0.62572\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0302 - loss: 0.5986 - val_accuracy: 0.0000e+00 - val_loss: 0.6303\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0312 - loss: 0.5625\n",
            "Epoch 9: val_loss did not improve from 0.62572\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0326 - loss: 0.5637 - val_accuracy: 0.0500 - val_loss: 0.6381\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0228 - loss: 0.5370\n",
            "Epoch 10: val_loss did not improve from 0.62572\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0222 - loss: 0.5391 - val_accuracy: 0.0000e+00 - val_loss: 0.6416\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0208 - loss: 0.5374\n",
            "Epoch 11: val_loss did not improve from 0.62572\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0186 - loss: 0.5346 - val_accuracy: 0.0000e+00 - val_loss: 0.6558\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0046 - loss: 0.5019    \n",
            "Epoch 12: val_loss did not improve from 0.62572\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0101 - loss: 0.5019 - val_accuracy: 0.0000e+00 - val_loss: 0.6574\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0247 - loss: 0.4811\n",
            "Epoch 13: val_loss did not improve from 0.62572\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0259 - loss: 0.4805 - val_accuracy: 0.0500 - val_loss: 0.6613\n",
            "\n",
            "  Completed 13 epochs (early stopped: True)\n",
            "  Final training loss: 0.4794\n",
            "  Final validation loss: 0.6613\n",
            "  Best validation loss: 0.6257\n",
            "\n",
            "  FOLD 1 RESULTS:\n",
            "    Accuracy:      0.1000\n",
            "    Precision:     0.5964\n",
            "    Recall:        1.0000\n",
            "    F1 Score:      0.7070\n",
            "    Hamming Loss:  0.4036\n",
            "    Hamming Accuracy:     0.5964\n",
            "    F1 Macro:             0.7320\n",
            "    F1 Micro:             0.7472\n",
            "    Jaccard (samples):    0.5964\n",
            "\n",
            "  FOLD 2/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0247 - loss: 0.6906\n",
            "Epoch 1: val_loss improved from inf to 0.66463, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 210ms/step - accuracy: 0.0233 - loss: 0.6887 - val_accuracy: 0.0000e+00 - val_loss: 0.6646\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0410 - loss: 0.6631\n",
            "Epoch 2: val_loss improved from 0.66463 to 0.61710, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.0388 - loss: 0.6609 - val_accuracy: 0.1500 - val_loss: 0.6171\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0443 - loss: 0.6362\n",
            "Epoch 3: val_loss improved from 0.61710 to 0.60577, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0455 - loss: 0.6347 - val_accuracy: 0.1500 - val_loss: 0.6058\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0840 - loss: 0.6338\n",
            "Epoch 4: val_loss did not improve from 0.60577\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0834 - loss: 0.6349 - val_accuracy: 0.1500 - val_loss: 0.6173\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0710 - loss: 0.6154\n",
            "Epoch 5: val_loss did not improve from 0.60577\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0656 - loss: 0.6145 - val_accuracy: 0.1500 - val_loss: 0.6107\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0371 - loss: 0.6223\n",
            "Epoch 6: val_loss improved from 0.60577 to 0.60006, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0453 - loss: 0.6239 - val_accuracy: 0.1500 - val_loss: 0.6001\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0150 - loss: 0.6048    \n",
            "Epoch 7: val_loss improved from 0.60006 to 0.59820, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold2.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0214 - loss: 0.6069 - val_accuracy: 0.1500 - val_loss: 0.5982\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0339 - loss: 0.6048    \n",
            "Epoch 8: val_loss did not improve from 0.59820\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0477 - loss: 0.6068 - val_accuracy: 0.1500 - val_loss: 0.6007\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0853 - loss: 0.6121\n",
            "Epoch 9: val_loss did not improve from 0.59820\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0774 - loss: 0.6085 - val_accuracy: 0.1500 - val_loss: 0.6020\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0547 - loss: 0.5787\n",
            "Epoch 10: val_loss did not improve from 0.59820\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0524 - loss: 0.5765 - val_accuracy: 0.1500 - val_loss: 0.6078\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0254 - loss: 0.5627    \n",
            "Epoch 11: val_loss did not improve from 0.59820\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0283 - loss: 0.5619 - val_accuracy: 0.1500 - val_loss: 0.6164\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0391 - loss: 0.5346\n",
            "Epoch 12: val_loss did not improve from 0.59820\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0375 - loss: 0.5316 - val_accuracy: 0.1500 - val_loss: 0.6421\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0553 - loss: 0.5045\n",
            "Epoch 13: val_loss did not improve from 0.59820\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0529 - loss: 0.5016 - val_accuracy: 0.1500 - val_loss: 0.6601\n",
            "\n",
            "  Completed 13 epochs (early stopped: True)\n",
            "  Final training loss: 0.4957\n",
            "  Final validation loss: 0.6601\n",
            "  Best validation loss: 0.5982\n",
            "\n",
            "  FOLD 2 RESULTS:\n",
            "    Accuracy:      0.2000\n",
            "    Precision:     0.6536\n",
            "    Recall:        1.0000\n",
            "    F1 Score:      0.7459\n",
            "    Hamming Loss:  0.3464\n",
            "    Hamming Accuracy:     0.6536\n",
            "    F1 Macro:             0.7803\n",
            "    F1 Micro:             0.7905\n",
            "    Jaccard (samples):    0.6536\n",
            "\n",
            "  FOLD 3/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0703 - loss: 0.6902\n",
            "Epoch 1: val_loss improved from inf to 0.68262, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 202ms/step - accuracy: 0.0674 - loss: 0.6889 - val_accuracy: 0.0000e+00 - val_loss: 0.6826\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0371 - loss: 0.6676\n",
            "Epoch 2: val_loss improved from 0.68262 to 0.66569, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0362 - loss: 0.6651 - val_accuracy: 0.0000e+00 - val_loss: 0.6657\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0885 - loss: 0.6488\n",
            "Epoch 3: val_loss improved from 0.66569 to 0.64835, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0864 - loss: 0.6448 - val_accuracy: 0.1000 - val_loss: 0.6484\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0345 - loss: 0.6103\n",
            "Epoch 4: val_loss improved from 0.64835 to 0.64122, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.0436 - loss: 0.6143 - val_accuracy: 0.0500 - val_loss: 0.6412\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0625 - loss: 0.6099\n",
            "Epoch 5: val_loss improved from 0.64122 to 0.63995, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0622 - loss: 0.6135 - val_accuracy: 0.0000e+00 - val_loss: 0.6400\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0749 - loss: 0.5988\n",
            "Epoch 6: val_loss improved from 0.63995 to 0.63773, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0727 - loss: 0.6026 - val_accuracy: 0.0000e+00 - val_loss: 0.6377\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0586 - loss: 0.6085\n",
            "Epoch 7: val_loss improved from 0.63773 to 0.63330, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.0619 - loss: 0.6069 - val_accuracy: 0.0000e+00 - val_loss: 0.6333\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0840 - loss: 0.5790\n",
            "Epoch 8: val_loss improved from 0.63330 to 0.62984, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0880 - loss: 0.5791 - val_accuracy: 0.0000e+00 - val_loss: 0.6298\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0807 - loss: 0.5575\n",
            "Epoch 9: val_loss did not improve from 0.62984\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0767 - loss: 0.5557 - val_accuracy: 0.0500 - val_loss: 0.6441\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0430 - loss: 0.5215    \n",
            "Epoch 10: val_loss did not improve from 0.62984\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.0560 - loss: 0.5222 - val_accuracy: 0.0000e+00 - val_loss: 0.6411\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0638 - loss: 0.5093\n",
            "Epoch 11: val_loss did not improve from 0.62984\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0745 - loss: 0.5085 - val_accuracy: 0.0500 - val_loss: 0.6316\n",
            "Epoch 12/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1159 - loss: 0.4952\n",
            "Epoch 12: val_loss did not improve from 0.62984\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1092 - loss: 0.4914 - val_accuracy: 0.0500 - val_loss: 0.6346\n",
            "Epoch 13/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0664 - loss: 0.4621\n",
            "Epoch 13: val_loss improved from 0.62984 to 0.62043, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0671 - loss: 0.4618 - val_accuracy: 0.1500 - val_loss: 0.6204\n",
            "Epoch 14/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1458 - loss: 0.4382\n",
            "Epoch 14: val_loss did not improve from 0.62043\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1315 - loss: 0.4400 - val_accuracy: 0.0500 - val_loss: 0.6216\n",
            "Epoch 15/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1126 - loss: 0.4657\n",
            "Epoch 15: val_loss improved from 0.62043 to 0.61971, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1093 - loss: 0.4586 - val_accuracy: 0.0500 - val_loss: 0.6197\n",
            "Epoch 16/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1764 - loss: 0.4416\n",
            "Epoch 16: val_loss did not improve from 0.61971\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1656 - loss: 0.4402 - val_accuracy: 0.0500 - val_loss: 0.6199\n",
            "Epoch 17/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1543 - loss: 0.4300\n",
            "Epoch 17: val_loss did not improve from 0.61971\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1577 - loss: 0.4270 - val_accuracy: 0.0500 - val_loss: 0.6219\n",
            "Epoch 18/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2018 - loss: 0.3948\n",
            "Epoch 18: val_loss improved from 0.61971 to 0.60927, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.2030 - loss: 0.3958 - val_accuracy: 0.0500 - val_loss: 0.6093\n",
            "Epoch 19/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2038 - loss: 0.4159\n",
            "Epoch 19: val_loss improved from 0.60927 to 0.60676, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.1998 - loss: 0.4098 - val_accuracy: 0.1000 - val_loss: 0.6068\n",
            "Epoch 20/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1393 - loss: 0.3927\n",
            "Epoch 20: val_loss did not improve from 0.60676\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1294 - loss: 0.3950 - val_accuracy: 0.1000 - val_loss: 0.6081\n",
            "Epoch 21/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1159 - loss: 0.3692\n",
            "Epoch 21: val_loss improved from 0.60676 to 0.60432, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold3.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.1161 - loss: 0.3757 - val_accuracy: 0.1000 - val_loss: 0.6043\n",
            "Epoch 22/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0911 - loss: 0.3810\n",
            "Epoch 22: val_loss did not improve from 0.60432\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0996 - loss: 0.3818 - val_accuracy: 0.1000 - val_loss: 0.6083\n",
            "Epoch 23/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0996 - loss: 0.3627\n",
            "Epoch 23: val_loss did not improve from 0.60432\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.0961 - loss: 0.3672 - val_accuracy: 0.0500 - val_loss: 0.6116\n",
            "Epoch 24/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1393 - loss: 0.3457\n",
            "Epoch 24: val_loss did not improve from 0.60432\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1340 - loss: 0.3502 - val_accuracy: 0.1000 - val_loss: 0.6079\n",
            "Epoch 25/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.1081 - loss: 0.3694\n",
            "Epoch 25: val_loss did not improve from 0.60432\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1063 - loss: 0.3681 - val_accuracy: 0.0500 - val_loss: 0.6115\n",
            "Epoch 26/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0970 - loss: 0.3624\n",
            "Epoch 26: val_loss did not improve from 0.60432\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.1080 - loss: 0.3589 - val_accuracy: 0.0500 - val_loss: 0.6141\n",
            "Epoch 27/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1204 - loss: 0.3553\n",
            "Epoch 27: val_loss did not improve from 0.60432\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1237 - loss: 0.3500 - val_accuracy: 0.1000 - val_loss: 0.6280\n",
            "\n",
            "  Completed 27 epochs (early stopped: False)\n",
            "  Final training loss: 0.3395\n",
            "  Final validation loss: 0.6280\n",
            "  Best validation loss: 0.6043\n",
            "\n",
            "  FOLD 3 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.7287\n",
            "    Recall:        0.6782\n",
            "    F1 Score:      0.6171\n",
            "    Hamming Loss:  0.3786\n",
            "    Hamming Accuracy:     0.6214\n",
            "    F1 Macro:             0.5944\n",
            "    F1 Micro:             0.6687\n",
            "    Jaccard (samples):    0.4819\n",
            "\n",
            "  FOLD 4/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 0.6901\n",
            "Epoch 1: val_loss improved from inf to 0.67686, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.0000e+00 - loss: 0.6889 - val_accuracy: 0.0000e+00 - val_loss: 0.6769\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 0.6716\n",
            "Epoch 2: val_loss improved from 0.67686 to 0.65031, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0000e+00 - loss: 0.6690 - val_accuracy: 0.0000e+00 - val_loss: 0.6503\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0000e+00 - loss: 0.6460\n",
            "Epoch 3: val_loss improved from 0.65031 to 0.62987, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.0000e+00 - loss: 0.6445 - val_accuracy: 0.0000e+00 - val_loss: 0.6299\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0085 - loss: 0.6346    \n",
            "Epoch 4: val_loss improved from 0.62987 to 0.62930, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.0079 - loss: 0.6343 - val_accuracy: 0.0000e+00 - val_loss: 0.6293\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0000e+00 - loss: 0.6125\n",
            "Epoch 5: val_loss improved from 0.62930 to 0.62430, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold4.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.0000e+00 - loss: 0.6169 - val_accuracy: 0.0000e+00 - val_loss: 0.6243\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0085 - loss: 0.6092    \n",
            "Epoch 6: val_loss did not improve from 0.62430\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0146 - loss: 0.6102 - val_accuracy: 0.0000e+00 - val_loss: 0.6274\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0163 - loss: 0.5902\n",
            "Epoch 7: val_loss did not improve from 0.62430\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0176 - loss: 0.5909 - val_accuracy: 0.0000e+00 - val_loss: 0.6262\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0130 - loss: 0.5607    \n",
            "Epoch 8: val_loss did not improve from 0.62430\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0176 - loss: 0.5645 - val_accuracy: 0.0000e+00 - val_loss: 0.6367\n",
            "Epoch 9/30\n",
            "\u001b[1m3/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.0035 - loss: 0.5665    \n",
            "Epoch 9: val_loss did not improve from 0.62430\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0088 - loss: 0.5608 - val_accuracy: 0.0000e+00 - val_loss: 0.6689\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0085 - loss: 0.5361    \n",
            "Epoch 10: val_loss did not improve from 0.62430\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0079 - loss: 0.5362 - val_accuracy: 0.0000e+00 - val_loss: 0.6825\n",
            "Epoch 11/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0065 - loss: 0.5351    \n",
            "Epoch 11: val_loss did not improve from 0.62430\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0088 - loss: 0.5317 - val_accuracy: 0.0000e+00 - val_loss: 0.6932\n",
            "\n",
            "  Completed 11 epochs (early stopped: True)\n",
            "  Final training loss: 0.5249\n",
            "  Final validation loss: 0.6932\n",
            "  Best validation loss: 0.6243\n",
            "\n",
            "  FOLD 4 RESULTS:\n",
            "    Accuracy:      0.2000\n",
            "    Precision:     0.6165\n",
            "    Recall:        0.9944\n",
            "    F1 Score:      0.7063\n",
            "    Hamming Loss:  0.3857\n",
            "    Hamming Accuracy:     0.6143\n",
            "    F1 Macro:             0.7482\n",
            "    F1 Micro:             0.7611\n",
            "    Jaccard (samples):    0.6143\n",
            "\n",
            "  FOLD 5/5\n",
            "  Training samples: 80, Validation samples: 20\n",
            "  Training...\n",
            "Epoch 1/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.0918 - loss: 0.6890\n",
            "Epoch 1: val_loss improved from inf to 0.67691, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 207ms/step - accuracy: 0.0800 - loss: 0.6875 - val_accuracy: 0.0000e+00 - val_loss: 0.6769\n",
            "Epoch 2/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0566 - loss: 0.6636\n",
            "Epoch 2: val_loss improved from 0.67691 to 0.66717, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0542 - loss: 0.6620 - val_accuracy: 0.0000e+00 - val_loss: 0.6672\n",
            "Epoch 3/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0130 - loss: 0.6395    \n",
            "Epoch 3: val_loss improved from 0.66717 to 0.66151, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.0157 - loss: 0.6378 - val_accuracy: 0.0000e+00 - val_loss: 0.6615\n",
            "Epoch 4/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0319 - loss: 0.6475    \n",
            "Epoch 4: val_loss improved from 0.66151 to 0.66070, saving model to /content/drive/MyDrive/lstm_keywords/models_1/lstm_units128_drop0.5_fold5.keras\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.0354 - loss: 0.6390 - val_accuracy: 0.0000e+00 - val_loss: 0.6607\n",
            "Epoch 5/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0293 - loss: 0.6114\n",
            "Epoch 5: val_loss did not improve from 0.66070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.0313 - loss: 0.6091 - val_accuracy: 0.0000e+00 - val_loss: 0.6647\n",
            "Epoch 6/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0111 - loss: 0.5703    \n",
            "Epoch 6: val_loss did not improve from 0.66070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0144 - loss: 0.5760 - val_accuracy: 0.0000e+00 - val_loss: 0.6634\n",
            "Epoch 7/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0326 - loss: 0.5613\n",
            "Epoch 7: val_loss did not improve from 0.66070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.0287 - loss: 0.5538 - val_accuracy: 0.0000e+00 - val_loss: 0.7115\n",
            "Epoch 8/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0540 - loss: 0.5548\n",
            "Epoch 8: val_loss did not improve from 0.66070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0595 - loss: 0.5470 - val_accuracy: 0.0000e+00 - val_loss: 0.7221\n",
            "Epoch 9/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0215 - loss: 0.4875    \n",
            "Epoch 9: val_loss did not improve from 0.66070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0237 - loss: 0.4902 - val_accuracy: 0.0000e+00 - val_loss: 0.6898\n",
            "Epoch 10/30\n",
            "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0521 - loss: 0.4753\n",
            "Epoch 10: val_loss did not improve from 0.66070\n",
            "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.0582 - loss: 0.4774 - val_accuracy: 0.0000e+00 - val_loss: 0.7697\n",
            "\n",
            "  Completed 10 epochs (early stopped: True)\n",
            "  Final training loss: 0.4817\n",
            "  Final validation loss: 0.7697\n",
            "  Best validation loss: 0.6607\n",
            "\n",
            "  FOLD 5 RESULTS:\n",
            "    Accuracy:      0.0000\n",
            "    Precision:     0.5654\n",
            "    Recall:        0.9546\n",
            "    F1 Score:      0.6713\n",
            "    Hamming Loss:  0.4357\n",
            "    Hamming Accuracy:     0.5643\n",
            "    F1 Macro:             0.6502\n",
            "    F1 Micro:             0.7067\n",
            "    Jaccard (samples):    0.5420\n",
            "\n",
            "================================================================================\n",
            "COMBINATION 4 SUMMARY\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.5, 'lstm_units': 128}\n",
            "Average Accuracy:      0.1000 (+/- 0.0894)\n",
            "Average Precision:     0.6321 (+/- 0.0561)\n",
            "Average Recall:        0.9254 (+/- 0.1248)\n",
            "Average F1 Score:      0.6895 (+/- 0.0432)\n",
            "Average Hamming Loss:  0.3900 (+/- 0.0294)\n",
            "Average Hamming Accuracy: 0.6100\n",
            "Average F1 Macro:         0.7010\n",
            "Average F1 Micro:         0.7348\n",
            "Average Jaccard (samples):0.5776\n",
            "Completed at: 19:41:07\n",
            "\n",
            "âœ“ Results saved to /content/drive/MyDrive/lstm_keywords/results_1/grid_search_results.json\n",
            "\n",
            "\n",
            "================================================================================\n",
            "GRID SEARCH COMPLETED!\n",
            "================================================================================\n",
            "Finished at: 2025-12-03 19:41:07\n",
            "\n",
            "================================================================================\n",
            "CROSS-VALIDATION RESULTS (sorted by F1 score)\n",
            "================================================================================\n",
            "                                  params  accuracy_mean  accuracy_std  precision_mean  recall_mean  f1_mean   f1_std  hamming_loss_mean  f1_macro_mean  f1_micro_mean  hamming_accuracy_mean  jaccard_samples_mean\n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}           0.07      0.050990        0.618654     0.959820 0.705751 0.016356           0.385000       0.702549       0.748678               0.615000              0.595788\n",
            " {'dropout_rate': 0.5, 'lstm_units': 64}           0.02      0.024495        0.621863     0.926366 0.696035 0.026301           0.385714       0.690922       0.739417               0.614286              0.579785\n",
            " {'dropout_rate': 0.3, 'lstm_units': 64}           0.05      0.077460        0.613013     0.942639 0.695594 0.029646           0.398571       0.695132       0.737304               0.601429              0.580445\n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}           0.10      0.089443        0.632117     0.925442 0.689526 0.043232           0.390000       0.701012       0.734849               0.610000              0.577640\n",
            "\n",
            "âœ“ Final summary saved to 'final_grid_search_summary.csv'\n",
            "\n",
            "================================================================================\n",
            "BEST PARAMETERS\n",
            "================================================================================\n",
            "Parameters: {'dropout_rate': 0.3, 'lstm_units': 128}\n",
            "F1 Score: 0.7058 (+/- 0.0164)\n",
            "Accuracy: 0.0700 (+/- 0.0510)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EIgJjgYqvYFr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation of My Results\n",
        "\n",
        "Using the F1_macro and Jaccard sample metrics,   \n",
        "the Friedman tests and post-hoc Nemenyi tests."
      ],
      "metadata": {
        "id": "EpFmcuzuIo6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-posthocs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv2Hg9bUKk7F",
        "outputId": "fe9fa028-ca45-4a47-be13-a253c8f0adf4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-posthocs\n",
            "  Downloading scikit_posthocs-0.11.4-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from scikit-posthocs) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from scikit-posthocs) (1.16.3)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from scikit-posthocs) (0.14.5)\n",
            "Requirement already satisfied: pandas>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from scikit-posthocs) (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from scikit-posthocs) (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from scikit-posthocs) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.20.0->scikit-posthocs) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->scikit-posthocs) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->scikit-posthocs) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->scikit-posthocs) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->scikit-posthocs) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->scikit-posthocs) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->scikit-posthocs) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->scikit-posthocs) (3.2.5)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->scikit-posthocs) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.20.0->scikit-posthocs) (1.17.0)\n",
            "Downloading scikit_posthocs-0.11.4-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: scikit-posthocs\n",
            "Successfully installed scikit-posthocs-0.11.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import scikit_posthocs as sp\n",
        "from scipy.stats import friedmanchisquare"
      ],
      "metadata": {
        "id": "4zDzabNiJCZy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_metrics = ['f1_macro', 'jaccard_samples']\n",
        "\n",
        "for metric in key_metrics:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(f\"STATISTICAL TESTS FOR: {metric.upper()}\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    df = pd.DataFrame(metrics_all[metric])\n",
        "\n",
        "    # mean ranking\n",
        "    means = df.mean().sort_values(ascending=False)\n",
        "    print(\"\\nMean values:\")\n",
        "    print(means.round(4))\n",
        "\n",
        "    # Friedman's test\n",
        "    algorithms = [df[col].values for col in df.columns]\n",
        "\n",
        "    stat, p_value = friedmanchisquare(*algorithms)\n",
        "    print(f\"\\nTest Friedmana dla {metric}:\")\n",
        "    print(f\"chi2 = {stat:.4f}, p-value = {p_value:.6f}\")\n",
        "\n",
        "    # post-hoc Nemenyi\n",
        "    nemenyi = sp.posthoc_nemenyi_friedman(df.to_numpy())\n",
        "    nemenyi_df = pd.DataFrame(nemenyi, index=df.columns, columns=df.columns)\n",
        "\n",
        "    print(f\"\\nPost-hoc Nemenyi (p-values) â€“ {metric}:\")\n",
        "    print(nemenyi_df.round(4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFiPOknsJFDU",
        "outputId": "c5698607-ed42-4a72-c7be-2460722b3fe2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "STATISTICAL TESTS FOR: F1_MACRO\n",
            "================================================================================\n",
            "\n",
            "Mean values:\n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}    0.7025\n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}    0.7010\n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}     0.6951\n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}     0.6909\n",
            "dtype: float64\n",
            "\n",
            "Test Friedmana dla f1_macro:\n",
            "chi2 = 1.5625, p-value = 0.667922\n",
            "\n",
            "Post-hoc Nemenyi (p-values) â€“ f1_macro:\n",
            "                                          {'dropout_rate': 0.3, 'lstm_units': 64}  \\\n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}                                       NaN   \n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}                                      NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}                                       NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}                                      NaN   \n",
            "\n",
            "                                          {'dropout_rate': 0.3, 'lstm_units': 128}  \\\n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}                                        NaN   \n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}                                       NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}                                        NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}                                       NaN   \n",
            "\n",
            "                                          {'dropout_rate': 0.5, 'lstm_units': 64}  \\\n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}                                       NaN   \n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}                                      NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}                                       NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}                                      NaN   \n",
            "\n",
            "                                          {'dropout_rate': 0.5, 'lstm_units': 128}  \n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}                                        NaN  \n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}                                       NaN  \n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}                                        NaN  \n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}                                       NaN  \n",
            "\n",
            "================================================================================\n",
            "STATISTICAL TESTS FOR: JACCARD_SAMPLES\n",
            "================================================================================\n",
            "\n",
            "Mean values:\n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}    0.5958\n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}     0.5804\n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}     0.5798\n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}    0.5776\n",
            "dtype: float64\n",
            "\n",
            "Test Friedmana dla jaccard_samples:\n",
            "chi2 = 4.3125, p-value = 0.229637\n",
            "\n",
            "Post-hoc Nemenyi (p-values) â€“ jaccard_samples:\n",
            "                                          {'dropout_rate': 0.3, 'lstm_units': 64}  \\\n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}                                       NaN   \n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}                                      NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}                                       NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}                                      NaN   \n",
            "\n",
            "                                          {'dropout_rate': 0.3, 'lstm_units': 128}  \\\n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}                                        NaN   \n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}                                       NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}                                        NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}                                       NaN   \n",
            "\n",
            "                                          {'dropout_rate': 0.5, 'lstm_units': 64}  \\\n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}                                       NaN   \n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}                                      NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}                                       NaN   \n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}                                      NaN   \n",
            "\n",
            "                                          {'dropout_rate': 0.5, 'lstm_units': 128}  \n",
            "{'dropout_rate': 0.3, 'lstm_units': 64}                                        NaN  \n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}                                       NaN  \n",
            "{'dropout_rate': 0.5, 'lstm_units': 64}                                        NaN  \n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}                                       NaN  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "configs = list(metrics_all['f1_macro'].keys())\n",
        "\n",
        "comparison_rows = []\n",
        "\n",
        "for cfg in configs:\n",
        "    comparison_rows.append({\n",
        "        'config': cfg,\n",
        "        'f1_macro_mean': np.mean(metrics_all['f1_macro'][cfg]),\n",
        "        'jaccard_mean': np.mean(metrics_all['jaccard_samples'][cfg])\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_rows)\n",
        "\n",
        "\n",
        "comparison_df_sorted_f1 = comparison_df.sort_values('f1_macro_mean', ascending=False)\n",
        "comparison_df_sorted_jaccard = comparison_df.sort_values('jaccard_mean', ascending=False)\n",
        "\n",
        "best_f1 = comparison_df_sorted_f1.iloc[0]\n",
        "best_jaccard = comparison_df_sorted_jaccard.iloc[0]\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"PORÃ“WNANIE MODELI â€“ ÅšREDNIE F1 MACRO I JACCARD\")\n",
        "print(\"=\"*90)\n",
        "print(comparison_df.round(4).to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"NAJLEPSZY MODEL WG F1 MACRO\")\n",
        "print(\"=\"*90)\n",
        "print(f\"Config: {best_f1['config']}\")\n",
        "print(f\"F1 Macro Mean: {best_f1['f1_macro_mean']:.4f}\")\n",
        "print(f\"Jaccard Mean:  {best_f1['jaccard_mean']:.4f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*90)\n",
        "print(\"NAJLEPSZY MODEL WG JACCARD SAMPLES\")\n",
        "print(\"=\"*90)\n",
        "print(f\"Config: {best_jaccard['config']}\")\n",
        "print(f\"Jaccard Mean:  {best_jaccard['jaccard_mean']:.4f}\")\n",
        "print(f\"F1 Macro Mean: {best_jaccard['f1_macro_mean']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1LoCbyvLj38",
        "outputId": "c593bcc7-c67d-4670-d28a-92ce504f6074"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==========================================================================================\n",
            "PORÃ“WNANIE MODELI â€“ ÅšREDNIE F1 MACRO I JACCARD\n",
            "==========================================================================================\n",
            "                                  config  f1_macro_mean  jaccard_mean\n",
            " {'dropout_rate': 0.3, 'lstm_units': 64}         0.6951        0.5804\n",
            "{'dropout_rate': 0.3, 'lstm_units': 128}         0.7025        0.5958\n",
            " {'dropout_rate': 0.5, 'lstm_units': 64}         0.6909        0.5798\n",
            "{'dropout_rate': 0.5, 'lstm_units': 128}         0.7010        0.5776\n",
            "\n",
            "==========================================================================================\n",
            "NAJLEPSZY MODEL WG F1 MACRO\n",
            "==========================================================================================\n",
            "Config: {'dropout_rate': 0.3, 'lstm_units': 128}\n",
            "F1 Macro Mean: 0.7025\n",
            "Jaccard Mean:  0.5958\n",
            "\n",
            "==========================================================================================\n",
            "NAJLEPSZY MODEL WG JACCARD SAMPLES\n",
            "==========================================================================================\n",
            "Config: {'dropout_rate': 0.3, 'lstm_units': 128}\n",
            "Jaccard Mean:  0.5958\n",
            "F1 Macro Mean: 0.7025\n"
          ]
        }
      ]
    }
  ]
}